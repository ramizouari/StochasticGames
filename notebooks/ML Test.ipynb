{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "438a2d44-e94c-4588-8974-6ee1f0aa17ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-02 04:57:54.603900: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import mpg.mpgml.dataset.generator as mpgml_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c960dd-3d3b-4719-91e5-eefed2227594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import mpg.wrapper as mpgwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c185625b-20fc-481a-84a9-6ce875529551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mpg.graph.random_graph\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import tensorflow_probability as tfp\n",
    "import mpg.wrapper as mpgwrapper\n",
    "\n",
    "\n",
    "def _convert_sparse_matrix_to_sparse_tensor(X, shape_hint):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, shape_hint)\n",
    "\n",
    "\n",
    "def _stack_sparse_tensors(shape_hint, *A):\n",
    "    indices = []\n",
    "    values = []\n",
    "    for i, Z in enumerate(A):\n",
    "        for L, v in zip(Z.indices, Z.values):\n",
    "            indices.append([i, *L])\n",
    "            values.append(v)\n",
    "    return tf.sparse.SparseTensor(indices, values, shape_hint)\n",
    "\n",
    "\n",
    "def _as_tensor(A, as_dense: bool, shape_hint=None):\n",
    "    if as_dense:\n",
    "        return tf.convert_to_tensor(A.todense())\n",
    "    else:\n",
    "        return _convert_sparse_matrix_to_sparse_tensor(A, shape_hint)\n",
    "\n",
    "\n",
    "def _generate_instances(n, p, seed, cardinality: int, target: bool, as_graph: bool,\n",
    "                        adj_matrix: bool, weight_matrix: bool, as_dense: bool):\n",
    "    generator = np.random.Generator(np.random.MT19937(seed))\n",
    "    graph = mpg.graph.random_graph.gnp_random_mpg(n=n, p=p, seed=seed, method=\"fast\", loops=True,\n",
    "                                                  distribution=\"integers\", low=0, high=10, endpoint=True)\n",
    "    output = None\n",
    "    if as_graph:\n",
    "        output = graph\n",
    "    else:\n",
    "        if adj_matrix and weight_matrix:\n",
    "            A = _as_tensor(nx.adjacency_matrix(graph, weight=None), as_dense=as_dense, shape_hint=(n, n))\n",
    "            W = _as_tensor(nx.adjacency_matrix(graph, weight=\"weight\"), as_dense=as_dense, shape_hint=(n, n))\n",
    "            if as_dense:\n",
    "                output = tf.stack([A, W], axis=0)\n",
    "            else:\n",
    "                output = tf.cast(_stack_sparse_tensors((2, n, n), A, W), dtype=tf.float32)\n",
    "\n",
    "        elif adj_matrix:\n",
    "            output = tf.cast(_as_tensor(nx.adjacency_matrix(graph, weight=None), as_dense=as_dense, shape_hint=(n, n)),\n",
    "                             dtype=tf.float32)\n",
    "        elif weight_matrix:\n",
    "            output = tf.cast(\n",
    "                _as_tensor(nx.adjacency_matrix(graph, weight=\"weight\"), as_dense=as_dense, shape_hint=(n, n)),\n",
    "                dtype=tf.float32)\n",
    "    starting = tf.constant([generator.integers(0, n), generator.integers(0, 1, endpoint=True)])\n",
    "    if target:\n",
    "        # TODO: Add target\n",
    "        return (output, starting, 1)\n",
    "    else:\n",
    "        return (output, 1)\n",
    "\n",
    "def cast_all(dtype,*args):\n",
    "    return tuple(tf.cast(arg, dtype) for arg in args)\n",
    "\n",
    "\n",
    "def _adj_matrix_generator(n, p):\n",
    "    A = np.zeros([n, n], dtype=np.uint8)\n",
    "    for k in range(n):\n",
    "        A[k, :] = np.random.binomial(1, p, n)\n",
    "        while A[k, :].sum() == 0:\n",
    "            A[k, :] = np.random.binomial(1, p, n)\n",
    "    return A\n",
    "\n",
    "def _generate_dense_instances(n, p, seeder, cardinality: int, target: bool, weight_matrix: bool, flatten: bool,\n",
    "                              weight_distribution: tfp.distributions.Distribution, weight_type):\n",
    "    adjacency_distribution: tfp.distributions.Distribution = tfp.distributions.Bernoulli(probs=p, dtype=tf.bool)\n",
    "    turn_distribution: tfp.distributions.Distribution = tfp.distributions.Bernoulli(probs=0.5)\n",
    "    # discrete=tfp.distributions.DiscreteUniform(low=0,high=10)\n",
    "    shape = (n, n) if not flatten else (n * n,)\n",
    "    W = weight_distribution.sample(shape, seed=seeder())\n",
    "    dtype = weight_distribution.dtype\n",
    "    A = tf.numpy_function(_adj_matrix_generator, inp=[n, p], Tout=tf.uint8,stateful=True)\n",
    "    if flatten:\n",
    "        A = tf.reshape(A, shape=(n*n,))\n",
    "    A = tf.cast(A, dtype=dtype)\n",
    "    W = tf.multiply(A, W)\n",
    "    vertex = tf.random.uniform((1,), 0, n, dtype=tf.int32, seed=seeder())\n",
    "    player = turn_distribution.sample((1,), seed=seeder())\n",
    "    if flatten:\n",
    "        if weight_matrix:\n",
    "            output = tf.concat(cast_all(dtype, A, W, vertex, player), axis=0)\n",
    "        else:\n",
    "            output = tf.concat(cast_all(dtype, A, vertex, player), axis=0)\n",
    "        if target:\n",
    "            if weight_type == tf.int32 or weight_type == tf.int64:\n",
    "                target_value = tf.py_function(\n",
    "                    lambda output: mpgwrapper.mpgcpp.winners_tensorflow_int_matrix_flattened_cxx(\n",
    "                        output.numpy().astype(np.int32).tolist()),\n",
    "                    inp=[output], Tout=tf.int32)\n",
    "            else:\n",
    "                target_value = tf.py_function(\n",
    "                    lambda output: mpgwrapper.mpgcpp.winners_tensorflow_float_matrix_flattened_cxx(\n",
    "                        output.numpy().astype(np.float32).tolist()),\n",
    "                    inp=[output], Tout=tf.float32)\n",
    "            target_value = tf.reshape(tf.ensure_shape(target_value, ()), shape=(1,))\n",
    "            return (tf.cast(output, dtype=tf.float32), tf.cast(target_value, dtype=tf.float32))\n",
    "        return output\n",
    "    else:\n",
    "        if weight_matrix:\n",
    "            output = tf.cast(tf.stack([A, W], axis=0), dtype=tf.float32)\n",
    "        else:\n",
    "            output = tf.cast(A, dtype=tf.float32)\n",
    "        if target:\n",
    "            return (output, tf.constant([vertex, player]), 1)\n",
    "        return (output, tf.constant([vertex, player]))\n",
    "\n",
    "\n",
    "class MPGGeneratedDenseDataset(tf.data.Dataset):\n",
    "\n",
    "    def __new__(cls, n, p, cardinality=tf.data.INFINITE_CARDINALITY,\n",
    "                target: bool = False, weight_matrix: bool = True, flatten=False, seed=None,\n",
    "                weights_distribution: tfp.distributions.Distribution = None,\n",
    "                weight_type : str = \"int\"):\n",
    "        if weight_type == \"int\":\n",
    "            weight_type= tf.int32\n",
    "        elif weight_type == \"float\":\n",
    "            weight_type = tf.float32\n",
    "        elif weight_type == \"double\":\n",
    "            weight_type = tf.float64\n",
    "        elif not isinstance(weight_type, tf.DType):\n",
    "            raise ValueError(\"weight_type must be a string or a tf.DType\")\n",
    "        if weights_distribution is None:\n",
    "            weights_distribution = tfp.distributions.Uniform(low=-1, high=1)\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(0, 1 << 32)\n",
    "\n",
    "        seeder = tfp.util.SeedStream(seed, \"seeding_generator\")\n",
    "\n",
    "        shape = None\n",
    "        if flatten:\n",
    "            if weight_matrix:\n",
    "                shape = (2 * n * n + 2,)\n",
    "            else:\n",
    "                shape = (n * n + 2,)\n",
    "            signature = (tf.TensorSpec(shape=shape, dtype=tf.float32),)\n",
    "        else:\n",
    "            if weight_matrix:\n",
    "                shape = (2, n, n)\n",
    "            else:\n",
    "                shape = (n, n)\n",
    "            signature = (tf.TensorSpec(shape=shape, dtype=tf.float32), tf.TensorSpec(shape=(2,), dtype=tf.int32))\n",
    "        if target:\n",
    "            signature = (*signature, tf.TensorSpec(shape=()))\n",
    "\n",
    "        generated: tf.data.Dataset\n",
    "        if cardinality == tf.data.INFINITE_CARDINALITY:\n",
    "            generated = tf.data.Dataset.counter(start=seed, step=1)\n",
    "        else:\n",
    "            generated = tf.data.Dataset.range(seed, seed + cardinality)\n",
    "        return generated.map(\n",
    "            lambda seed: _generate_dense_instances(n, p, seeder, cardinality, target, weight_matrix, flatten,\n",
    "                                                   weights_distribution, weight_type),\n",
    "            num_parallel_calls=12\n",
    "        )\n",
    "        #    range,\n",
    "        #    args=(n,p,cardinality, target, weight_matrix,flatten),\n",
    "        #    output_signature=signature\n",
    "        # )\n",
    "\n",
    "    def __init__(self, n, p, cardinality=tf.data.INFINITE_CARDINALITY,\n",
    "                 target: bool = False, weight_matrix: bool = True, flatten=False, seed=None,\n",
    "                 weights_distribution: tfp.distributions.Distribution = None,\n",
    "                 weight_type : str = \"int\"):\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.cardinality = cardinality\n",
    "        self.target = target\n",
    "        self.weight_matrix = weight_matrix\n",
    "        self.flatten = flatten\n",
    "        self.seed = seed\n",
    "        self.weights_distribution = weights_distribution\n",
    "\n",
    "    def _permutation(self, x, P):\n",
    "        if self.flatten:\n",
    "            S = tf.concat(tf.reshape(tf.tensordot(P, P, axes=None), shape=(-1,)))\n",
    "            return tf.concat([tf.gather(x, S, axis=0), P[x[-2]], x[-1]])\n",
    "\n",
    "    def permutation(self, P):\n",
    "        return self.map(lambda x: self._permutation(x, P))\n",
    "\n",
    "\n",
    "class MPGGeneratedDataset(tf.data.Dataset):\n",
    "    def _generator(n, p, cardinality: int, target: bool, as_graph: bool,\n",
    "                   adj_matrix: bool, weight_matrix: bool, as_dense: bool):\n",
    "        if cardinality == tf.data.INFINITE_CARDINALITY:\n",
    "            seed = 0\n",
    "            while True:\n",
    "                yield _generate_instances(n, p, seed, cardinality, target, as_graph, adj_matrix, weight_matrix,\n",
    "                                          as_dense)\n",
    "                seed += 1\n",
    "        else:\n",
    "            for sample_idx in range(cardinality):\n",
    "                yield _generate_instances(n, p, sample_idx, cardinality, target, as_graph, adj_matrix, weight_matrix,\n",
    "                                          as_dense)\n",
    "\n",
    "    def __new__(cls, n, p, cardinality=tf.data.INFINITE_CARDINALITY, target: bool = False, as_graph: bool = False,\n",
    "                adj_matrix: bool = True, weight_matrix: bool = True, as_dense: bool = True):\n",
    "        shape = None\n",
    "        if as_graph:\n",
    "            signature = tf.TensorSpec(shape=(), dtype=mpg.MeanPayoffGraph)\n",
    "        else:\n",
    "            if adj_matrix and weight_matrix:\n",
    "                shape = (2, n, n)\n",
    "            elif adj_matrix or weight_matrix:\n",
    "                shape = (n, n)\n",
    "            else:\n",
    "                raise ValueError(\"Must specify at least one of adj_matrix or weight_matrix\")\n",
    "        if as_dense:\n",
    "            TensorSpec = tf.TensorSpec\n",
    "        else:\n",
    "            TensorSpec = tf.SparseTensorSpec\n",
    "        signature = (TensorSpec(shape=shape), tf.TensorSpec(shape=(2,), dtype=tf.int32))\n",
    "        if target:\n",
    "            signature = (*signature, tf.TensorSpec(shape=()))\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            args=(n, p, cardinality, target, as_graph, adj_matrix, weight_matrix, as_dense),\n",
    "            output_signature=signature\n",
    "        )\n",
    "\n",
    "    def __init__(self, n, p):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a46f66e0-4827-474a-bf22-d0e0788591a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=MPGGeneratedDenseDataset(10,0.2,target=True,weight_matrix=True,flatten=True,weights_distribution=tfp.distributions.Uniform(-10,10),weight_type=\"int\")\n",
    "transformed=dataset.batch(64).take(1024).cache().repeat()\n",
    "validation_dataset=MPGGeneratedDenseDataset(10,0.2,target=True,weight_matrix=True,flatten=True,weights_distribution=tfp.distributions.Uniform(-10,10),weight_type=\"float\").batch(64).take(12).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b260d6d6-826e-47bd-8460-911a67b5da17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]], shape=(64, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 17:47:27.951136: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for x,y in validation_dataset.take(1):\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "224616e8-f5f7-4193-a904-2bad8b99c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpg.mpgml.layers.normalisation as mpgml_norm\n",
    "import mpg.mpgml.layers.augmentation as mpgml_augm\n",
    "import tensorflow.keras as keras\n",
    "model=keras.Sequential([\n",
    "    mpgml_norm.EdgeNormalisationLayer(edges_interval=(1,-2)),\n",
    "    mpgml_augm.EdgeWeightsNoiseLayer(noise_layer=keras.layers.GaussianNoise(stddev=0.01),edges_interval=(1,-2)),\n",
    "    keras.layers.Dense(100,activation=\"relu\"),\n",
    "    keras.layers.Dense(50,activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(50,activation=\"relu\"),\n",
    "    keras.layers.Dense(15,activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(15,activation=\"relu\"),\n",
    "    keras.layers.Dense(1,\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b8d1fa73-a6f7-4b3f-8839-9bab25d075dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "64/64 [==============================] - 11s 145ms/step - loss: 0.7165 - accuracy: 0.5251 - val_loss: 0.6990 - val_accuracy: 0.4909\n",
      "Epoch 2/25\n",
      "64/64 [==============================] - 7s 109ms/step - loss: 0.6840 - accuracy: 0.5667 - val_loss: 0.6896 - val_accuracy: 0.5378\n",
      "Epoch 3/25\n",
      "64/64 [==============================] - 7s 111ms/step - loss: 0.6683 - accuracy: 0.5891 - val_loss: 0.6804 - val_accuracy: 0.5729\n",
      "Epoch 4/25\n",
      "64/64 [==============================] - 7s 117ms/step - loss: 0.6629 - accuracy: 0.6074 - val_loss: 0.6689 - val_accuracy: 0.6016\n",
      "Epoch 5/25\n",
      "64/64 [==============================] - 7s 107ms/step - loss: 0.6331 - accuracy: 0.6404 - val_loss: 0.6676 - val_accuracy: 0.5990\n",
      "Epoch 6/25\n",
      "64/64 [==============================] - 7s 106ms/step - loss: 0.6291 - accuracy: 0.6487 - val_loss: 0.6739 - val_accuracy: 0.6042\n",
      "Epoch 7/25\n",
      "64/64 [==============================] - 7s 112ms/step - loss: 0.6377 - accuracy: 0.6392 - val_loss: 0.6661 - val_accuracy: 0.5924\n",
      "Epoch 8/25\n",
      "64/64 [==============================] - 7s 110ms/step - loss: 0.6298 - accuracy: 0.6431 - val_loss: 0.6649 - val_accuracy: 0.5820\n",
      "Epoch 9/25\n",
      "64/64 [==============================] - 7s 111ms/step - loss: 0.6273 - accuracy: 0.6445 - val_loss: 0.6691 - val_accuracy: 0.5859\n",
      "Epoch 10/25\n",
      "64/64 [==============================] - 7s 113ms/step - loss: 0.6275 - accuracy: 0.6470 - val_loss: 0.6740 - val_accuracy: 0.5951\n",
      "Epoch 11/25\n",
      "64/64 [==============================] - 7s 113ms/step - loss: 0.6274 - accuracy: 0.6497 - val_loss: 0.6697 - val_accuracy: 0.5951\n",
      "Epoch 12/25\n",
      "64/64 [==============================] - 7s 110ms/step - loss: 0.6302 - accuracy: 0.6458 - val_loss: 0.6649 - val_accuracy: 0.6029\n",
      "Epoch 13/25\n",
      "64/64 [==============================] - 7s 112ms/step - loss: 0.6307 - accuracy: 0.6418 - val_loss: 0.6622 - val_accuracy: 0.6003\n",
      "Epoch 14/25\n",
      "64/64 [==============================] - 7s 113ms/step - loss: 0.6261 - accuracy: 0.6475 - val_loss: 0.6589 - val_accuracy: 0.6107\n",
      "Epoch 15/25\n",
      "64/64 [==============================] - 7s 116ms/step - loss: 0.6171 - accuracy: 0.6604 - val_loss: 0.6636 - val_accuracy: 0.5990\n",
      "Epoch 16/25\n",
      "64/64 [==============================] - 7s 109ms/step - loss: 0.6335 - accuracy: 0.6350 - val_loss: 0.6594 - val_accuracy: 0.5977\n",
      "Epoch 17/25\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 0.6128 - accuracy: 0.6602 - val_loss: 0.6703 - val_accuracy: 0.5885\n",
      "Epoch 18/25\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.6085 - accuracy: 0.6692 - val_loss: 0.6724 - val_accuracy: 0.5898\n",
      "Epoch 19/25\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 0.6160 - accuracy: 0.6606 - val_loss: 0.6726 - val_accuracy: 0.5846\n",
      "Epoch 20/25\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.6298 - accuracy: 0.6443 - val_loss: 0.6698 - val_accuracy: 0.5807\n",
      "Epoch 21/25\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.6055 - accuracy: 0.6719 - val_loss: 0.6785 - val_accuracy: 0.5703\n",
      "Epoch 22/25\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.6066 - accuracy: 0.6709 - val_loss: 0.6700 - val_accuracy: 0.5820\n",
      "Epoch 23/25\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 0.6153 - accuracy: 0.6704 - val_loss: 0.6664 - val_accuracy: 0.5911\n",
      "Epoch 24/25\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.6124 - accuracy: 0.6675 - val_loss: 0.6686 - val_accuracy: 0.5885\n",
      "Epoch 25/25\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.6100 - accuracy: 0.6624 - val_loss: 0.6728 - val_accuracy: 0.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2170048f70>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"Adam\",\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(x=transformed,\n",
    "    epochs=25,\n",
    "    verbose='auto',\n",
    "    steps_per_epoch=64,\n",
    "    shuffle=False,\n",
    "          validation_data=validation_dataset\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6b742d82-9f2b-48a4-9e09-ac865e8f6563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "256/256 [==============================] - 154s 571ms/step - loss: 0.6104 - accuracy: 0.6830 - val_loss: 0.5711 - val_accuracy: 0.7174\n",
      "Epoch 2/25\n",
      "256/256 [==============================] - 130s 510ms/step - loss: 0.5925 - accuracy: 0.6843 - val_loss: 0.5641 - val_accuracy: 0.7266\n",
      "Epoch 3/25\n",
      "256/256 [==============================] - 125s 488ms/step - loss: 0.5786 - accuracy: 0.6942 - val_loss: 0.5572 - val_accuracy: 0.7266\n",
      "Epoch 4/25\n",
      "256/256 [==============================] - 116s 454ms/step - loss: 0.5746 - accuracy: 0.6968 - val_loss: 0.5532 - val_accuracy: 0.7448\n",
      "Epoch 5/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5543 - accuracy: 0.7164 - val_loss: 0.5561 - val_accuracy: 0.7422\n",
      "Epoch 6/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5666 - accuracy: 0.7048 - val_loss: 0.5574 - val_accuracy: 0.7292\n",
      "Epoch 7/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5582 - accuracy: 0.7106 - val_loss: 0.5586 - val_accuracy: 0.7383\n",
      "Epoch 8/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5588 - accuracy: 0.7123 - val_loss: 0.5592 - val_accuracy: 0.7292\n",
      "Epoch 9/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5488 - accuracy: 0.7214 - val_loss: 0.5605 - val_accuracy: 0.7279\n",
      "Epoch 10/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5553 - accuracy: 0.7130 - val_loss: 0.5587 - val_accuracy: 0.7318\n",
      "Epoch 11/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5508 - accuracy: 0.7155 - val_loss: 0.5577 - val_accuracy: 0.7344\n",
      "Epoch 12/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5515 - accuracy: 0.7176 - val_loss: 0.5569 - val_accuracy: 0.7357\n",
      "Epoch 13/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5425 - accuracy: 0.7241 - val_loss: 0.5610 - val_accuracy: 0.7240\n",
      "Epoch 14/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5512 - accuracy: 0.7150 - val_loss: 0.5585 - val_accuracy: 0.7279\n",
      "Epoch 15/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5424 - accuracy: 0.7256 - val_loss: 0.5543 - val_accuracy: 0.7266\n",
      "Epoch 16/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5450 - accuracy: 0.7235 - val_loss: 0.5591 - val_accuracy: 0.7135\n",
      "Epoch 17/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5370 - accuracy: 0.7321 - val_loss: 0.5659 - val_accuracy: 0.7240\n",
      "Epoch 18/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5422 - accuracy: 0.7253 - val_loss: 0.5594 - val_accuracy: 0.7201\n",
      "Epoch 19/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5375 - accuracy: 0.7289 - val_loss: 0.5637 - val_accuracy: 0.7135\n",
      "Epoch 20/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5382 - accuracy: 0.7256 - val_loss: 0.5669 - val_accuracy: 0.7031\n",
      "Epoch 21/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5306 - accuracy: 0.7366 - val_loss: 0.5651 - val_accuracy: 0.7227\n",
      "Epoch 22/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5362 - accuracy: 0.7289 - val_loss: 0.5684 - val_accuracy: 0.7266\n",
      "Epoch 23/25\n",
      "256/256 [==============================] - 2s 6ms/step - loss: 0.5257 - accuracy: 0.7365 - val_loss: 0.5654 - val_accuracy: 0.7070\n",
      "Epoch 24/25\n",
      "256/256 [==============================] - 2s 7ms/step - loss: 0.5317 - accuracy: 0.7325 - val_loss: 0.5638 - val_accuracy: 0.7057\n",
      "Epoch 25/25\n",
      "256/256 [==============================] - 2s 7ms/step - loss: 0.5239 - accuracy: 0.7383 - val_loss: 0.5709 - val_accuracy: 0.7201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f24e85dbbb0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=transformed,\n",
    "    epochs=25,\n",
    "    verbose='auto',\n",
    "    steps_per_epoch=256,\n",
    "    shuffle=False,\n",
    "          validation_data=validation_dataset\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1e738124-3e9d-4d50-8259-b17c518a89fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 05:43:34.998569: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y=next(iter(transformed))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da251eac-2296-4362-a6bf-c3fe4fd7dea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 5), dtype=float32, numpy=\n",
       "array([[  0.,   0.,   0.,   1.,   1.],\n",
       "       [  0.,   0.,   0.,   1.,   0.],\n",
       "       [  0.,   0.,  11.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   5.,   1.],\n",
       "       [  0.,   0.,   0.,   7.,   1.],\n",
       "       [  0.,   0.,   0.,   1.,   0.],\n",
       "       [  0., -94.,   0.,   4.,   1.],\n",
       "       [  0.,   0.,   0.,   3.,   0.],\n",
       "       [  0.,   0.,   0.,   6.,   1.],\n",
       "       [ 88.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   4.,   1.],\n",
       "       [  0.,   0.,   0.,   6.,   0.],\n",
       "       [  0., -66., -31.,   8.,   1.],\n",
       "       [  0.,   0.,   0.,   3.,   1.],\n",
       "       [  0.,   0.,  25.,   4.,   1.],\n",
       "       [ 61.,   0.,   0.,   6.,   0.],\n",
       "       [  0.,   0., -92.,   4.,   0.],\n",
       "       [-11.,   0.,   0.,   8.,   0.],\n",
       "       [  0.,   0.,   0.,   2.,   1.],\n",
       "       [  0.,  63.,   0.,   5.,   1.],\n",
       "       [  0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   4.,   0.],\n",
       "       [  0.,   0.,   0.,   5.,   1.],\n",
       "       [  0.,   0.,   0.,   1.,   1.],\n",
       "       [  0.,   0.,   0.,   4.,   1.],\n",
       "       [ 78.,   0.,   0.,   2.,   1.],\n",
       "       [ 44.,   0.,   0.,   4.,   0.],\n",
       "       [  0.,   0.,   0.,   8.,   1.],\n",
       "       [ 17.,   0., -54.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   6.,   1.],\n",
       "       [  0.,   0.,  80.,   6.,   1.],\n",
       "       [  0.,   0.,   0.,   6.,   1.],\n",
       "       [  0.,   0.,   0.,   7.,   1.],\n",
       "       [  0.,   0.,   0.,   4.,   0.],\n",
       "       [  0.,   0.,   0.,   7.,   0.],\n",
       "       [  0.,   0.,   0.,   5.,   1.],\n",
       "       [  0., -61.,   0.,   2.,   0.],\n",
       "       [  0.,   0.,  36.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   1.,   1.],\n",
       "       [  0.,   0.,  28.,   9.,   0.],\n",
       "       [  0.,   0.,   0.,   1.,   1.],\n",
       "       [  0.,   0.,   0.,   4.,   0.],\n",
       "       [ 73.,   0.,   0.,   6.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   1.],\n",
       "       [  0.,   0.,   0.,   4.,   1.],\n",
       "       [  0.,   0., -36.,   3.,   0.],\n",
       "       [  0.,   0.,   0.,   9.,   1.],\n",
       "       [  0., -67.,   0.,   1.,   0.],\n",
       "       [  0.,   0., -75.,   6.,   1.],\n",
       "       [  0.,   0.,   0.,   3.,   0.],\n",
       "       [  0.,   0.,   0.,   2.,   0.],\n",
       "       [-90.,   0.,   0.,   1.,   0.],\n",
       "       [  0.,   0.,   0.,   9.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   1.],\n",
       "       [  0.,   0.,   0.,   1.,   1.],\n",
       "       [  0.,   0.,  13.,   8.,   0.],\n",
       "       [  0.,   0.,  -4.,   2.,   0.],\n",
       "       [  0.,   0.,   0.,   3.,   0.],\n",
       "       [  0., -88.,   0.,   3.,   1.],\n",
       "       [  0.,   0., -80.,   0.,   0.],\n",
       "       [  0.,   0., -79.,   8.,   0.],\n",
       "       [  0.,   0.,   0.,   3.,   0.],\n",
       "       [  0.,   0., -64.,   8.,   0.],\n",
       "       [  0.,   0.,   0.,   6.,   1.]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x)[:,-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "76525fcd-f9d6-4fe6-8296-b8650bd55e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = mpg.graph.random_graph.gnp_random_mpg(10, 0.5, seed=1, method=\"fast\", loops=True,\n",
    "                                              distribution=\"integers\", low=0, high=10, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1ed80934-92d8-4292-bca8-6d68460daf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.convert_to_tensor(nx.adjacency_matrix(graph, weight=None).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f31b98bc-6320-4e42-a7de-0f7a271069a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coo = nx.adjacency_matrix(graph).tocoo()\n",
    "indices = np.mat([coo.row, coo.col]).transpose()\n",
    "Z=tf.SparseTensor(indices, coo.data, (10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88f34aa6-bae6-4e5a-988e-d463f4315552",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "binomial() takes at least 2 positional arguments (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mmtrand.pyx:3283\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.binomial\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: binomial() takes at least 2 positional arguments (0 given)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "381345b7-1bd3-44da-84b1-e7b56fe855d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mpg.graph.random_graph\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import tensorflow_probability as tfp\n",
    "import mpg.wrapper as mpgwrapper\n",
    "\n",
    "\n",
    "def _convert_sparse_matrix_to_sparse_tensor(X, shape_hint):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, shape_hint)\n",
    "\n",
    "\n",
    "def _stack_sparse_tensors(shape_hint, *A):\n",
    "    indices = []\n",
    "    values = []\n",
    "    for i, Z in enumerate(A):\n",
    "        for L, v in zip(Z.indices, Z.values):\n",
    "            indices.append([i, *L])\n",
    "            values.append(v)\n",
    "    return tf.sparse.SparseTensor(indices, values, shape_hint)\n",
    "\n",
    "\n",
    "def _as_tensor(A, as_dense: bool, shape_hint=None):\n",
    "    if as_dense:\n",
    "        return tf.convert_to_tensor(A.todense())\n",
    "    else:\n",
    "        return _convert_sparse_matrix_to_sparse_tensor(A, shape_hint)\n",
    "\n",
    "\n",
    "def _generate_instances(n, p, seed, cardinality: int, target: bool, as_graph: bool,\n",
    "                        adj_matrix: bool, weight_matrix: bool, as_dense: bool):\n",
    "    generator = np.random.Generator(np.random.MT19937(seed))\n",
    "    graph = mpg.graph.random_graph.gnp_random_mpg(n=n, p=p, seed=seed, method=\"fast\", loops=True,\n",
    "                                                  distribution=\"integers\", low=0, high=10, endpoint=True)\n",
    "    output = None\n",
    "    if as_graph:\n",
    "        output = graph\n",
    "    else:\n",
    "        if adj_matrix and weight_matrix:\n",
    "            A = _as_tensor(nx.adjacency_matrix(graph, weight=None), as_dense=as_dense, shape_hint=(n, n))\n",
    "            W = _as_tensor(nx.adjacency_matrix(graph, weight=\"weight\"), as_dense=as_dense, shape_hint=(n, n))\n",
    "            if as_dense:\n",
    "                output = tf.stack([A, W], axis=0)\n",
    "            else:\n",
    "                output = tf.cast(_stack_sparse_tensors((2, n, n), A, W), dtype=tf.float32)\n",
    "\n",
    "        elif adj_matrix:\n",
    "            output = tf.cast(_as_tensor(nx.adjacency_matrix(graph, weight=None), as_dense=as_dense, shape_hint=(n, n)),\n",
    "                             dtype=tf.float32)\n",
    "        elif weight_matrix:\n",
    "            output = tf.cast(\n",
    "                _as_tensor(nx.adjacency_matrix(graph, weight=\"weight\"), as_dense=as_dense, shape_hint=(n, n)),\n",
    "                dtype=tf.float32)\n",
    "    starting = tf.constant([generator.integers(0, n), generator.integers(0, 1, endpoint=True)])\n",
    "    if target:\n",
    "        # TODO: Add target\n",
    "        return (output, starting, 1)\n",
    "    else:\n",
    "        return (output, 1)\n",
    "\n",
    "\n",
    "def _generate_dense_instances(n, p, seed, cardinality: int, target: bool, weight_matrix: bool, flatten: bool):\n",
    "    seeder=tfp.util.SeedStream(seed.numpy(),\"seeding_generator\")\n",
    "    adjacency_distribution: tfp.distributions.Distribution = tfp.distributions.Bernoulli(probs=p)\n",
    "    turn_distribution: tfp.distributions.Distribution = tfp.distributions.Bernoulli(probs=0.5)\n",
    "    # discrete=tfp.distributions.DiscreteUniform(low=0,high=10)\n",
    "    shape = (n, n) if not flatten else (n * n,)\n",
    "    W = tf.random.uniform(shape,-100, 101, dtype=tf.int32,seed=seeder())\n",
    "    adjacency_list=[]\n",
    "    for k in range(n):\n",
    "        adjacency_list.append(adjacency_distribution.sample((n,),seed=seeder()))\n",
    "        while tf.math.reduce_all(adjacency_list[k]==0):\n",
    "            adjacency_list[k] = adjacency_distribution.sample((n,),seed=seeder())\n",
    "    A= tf.concat(adjacency_list,0)\n",
    "    W = tf.multiply(A, W)\n",
    "    vertex = tf.random.uniform((1,),0, n, dtype=np.int32,seed=seeder())\n",
    "    player = turn_distribution.sample((1,),seed=seeder())\n",
    "    if flatten:\n",
    "        if weight_matrix:\n",
    "            output = tf.cast(tf.concat([A, W, vertex, player], axis=0), dtype=tf.float32)\n",
    "        else:\n",
    "            output = tf.cast(tf.concat([A, W, vertex, player], axis=0), dtype=tf.float32)\n",
    "        if target:\n",
    "            target_value=tf.py_function(lambda output:mpgwrapper.mpgcpp.winners_tensorflow_integer_matrix_flattened_cxx(output.numpy().astype(int).tolist()),inp=[output],Tout=tf.int32)\n",
    "            target_value=tf.reshape(tf.ensure_shape(target_value,()),shape=(1,))\n",
    "            return (output, tf.cast(target_value,dtype=tf.float32))\n",
    "        return output\n",
    "    else:\n",
    "        if weight_matrix:\n",
    "            output = tf.cast(tf.stack([A, W], axis=0), dtype=tf.float32)\n",
    "        else:\n",
    "            output = tf.cast(A, dtype=tf.float32)\n",
    "        if target:\n",
    "            return (output, tf.constant([vertex, player]), 1)\n",
    "        return (output, tf.constant([vertex, player]))\n",
    "\n",
    "\n",
    "class MPGGeneratedDenseDataset(tf.data.Dataset):\n",
    "\n",
    "    def __new__(cls, n, p, cardinality=tf.data.INFINITE_CARDINALITY,\n",
    "                target: bool = False, weight_matrix: bool = True, flatten=False,seed=None,\n",
    "                weights_distribution: tfp.distributions.Distribution = None):\n",
    "        if weights_distribution is None:\n",
    "            weights_distribution = tfp.distributions.Uniform(low=-100, high=100)\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(0, 1<<32)\n",
    "        shape = None\n",
    "        if flatten:\n",
    "            if weight_matrix:\n",
    "                shape = (2 * n * n + 2,)\n",
    "            else:\n",
    "                shape = (n * n + 2,)\n",
    "            signature = (tf.TensorSpec(shape=shape, dtype=tf.float32),)\n",
    "        else:\n",
    "            if weight_matrix:\n",
    "                shape = (2, n, n)\n",
    "            else:\n",
    "                shape = (n, n)\n",
    "            signature = (tf.TensorSpec(shape=shape, dtype=tf.float32), tf.TensorSpec(shape=(2,), dtype=tf.int32))\n",
    "        if target:\n",
    "            signature = (*signature, tf.TensorSpec(shape=()))\n",
    "\n",
    "        generated: tf.data.Dataset\n",
    "        if cardinality == tf.data.INFINITE_CARDINALITY:\n",
    "            generated = tf.data.Dataset.counter(start=seed, step=1)\n",
    "        else:\n",
    "            generated = tf.data.Dataset.range(seed,seed+cardinality)\n",
    "        return generated.map(\n",
    "            lambda seed: _generate_dense_instances(n, p, seed, cardinality, target, weight_matrix, flatten),\n",
    "            num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    "        )\n",
    "        #    range,\n",
    "        #    args=(n,p,cardinality, target, weight_matrix,flatten),\n",
    "        #    output_signature=signature\n",
    "        # )\n",
    "\n",
    "    def __init__(self, n, p, cardinality=tf.data.INFINITE_CARDINALITY,\n",
    "                target: bool = False, weight_matrix: bool = True, flatten=False,seed=None,\n",
    "                weights_distribution: tfp.distributions.Distribution = None):\n",
    "        self.n=n\n",
    "        self.p=p\n",
    "        self.cardinality=cardinality\n",
    "        self.target=target\n",
    "        self.weight_matrix=weight_matrix\n",
    "        self.flatten=flatten\n",
    "        self.seed=seed\n",
    "        self.weights_distribution=weights_distribution\n",
    "\n",
    "\n",
    "    def _permutation(self,x,P):\n",
    "        if self.flatten:\n",
    "            S = tf.concat(tf.reshape(tf.tensordot(P, P, axes=None), shape=(-1,)))\n",
    "            return tf.concat([tf.gather(x,S,axis=0),P[x[-2]],x[-1]])\n",
    "\n",
    "    def permutation(self,P):\n",
    "        return self.map(lambda x: self._permutation(x,P))\n",
    "\n",
    "\n",
    "class MPGGeneratedDataset(tf.data.Dataset):\n",
    "    def _generator(n, p, cardinality: int, target: bool, as_graph: bool,\n",
    "                   adj_matrix: bool, weight_matrix: bool, as_dense: bool):\n",
    "        if cardinality == tf.data.INFINITE_CARDINALITY:\n",
    "            seed = 0\n",
    "            while True:\n",
    "                yield _generate_instances(n, p, seed, cardinality, target, as_graph, adj_matrix, weight_matrix,\n",
    "                                          as_dense)\n",
    "                seed += 1\n",
    "        else:\n",
    "            for sample_idx in range(cardinality):\n",
    "                yield _generate_instances(n, p, sample_idx, cardinality, target, as_graph, adj_matrix, weight_matrix,\n",
    "                                          as_dense)\n",
    "\n",
    "    def __new__(cls, n, p, cardinality=tf.data.INFINITE_CARDINALITY, target: bool = False, as_graph: bool = False,\n",
    "                adj_matrix: bool = True, weight_matrix: bool = True, as_dense: bool = True):\n",
    "        shape = None\n",
    "        if as_graph:\n",
    "            signature = tf.TensorSpec(shape=(), dtype=mpg.MeanPayoffGraph)\n",
    "        else:\n",
    "            if adj_matrix and weight_matrix:\n",
    "                shape = (2, n, n)\n",
    "            elif adj_matrix or weight_matrix:\n",
    "                shape = (n, n)\n",
    "            else:\n",
    "                raise ValueError(\"Must specify at least one of adj_matrix or weight_matrix\")\n",
    "        if as_dense:\n",
    "            TensorSpec = tf.TensorSpec\n",
    "        else:\n",
    "            TensorSpec = tf.SparseTensorSpec\n",
    "        signature = (TensorSpec(shape=shape), tf.TensorSpec(shape=(2,), dtype=tf.int32))\n",
    "        if target:\n",
    "            signature = (*signature, tf.TensorSpec(shape=()))\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls._generator,\n",
    "            args=(n, p, cardinality, target, as_graph, adj_matrix, weight_matrix, as_dense),\n",
    "            output_signature=signature\n",
    "        )\n",
    "\n",
    "    def __init__(self, n, p):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a221f6ba-9aaf-4185-bae0-97da9546647b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7fad8dbf60c0>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(range(2),Z.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ac159200-e868-4a3d-bbd0-2c99c86982a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor([0 5], shape=(2,), dtype=int64)\n",
      "tf.Tensor([0 8], shape=(2,), dtype=int64)\n",
      "tf.Tensor([0 9], shape=(2,), dtype=int64)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor([1 2], shape=(2,), dtype=int64)\n",
      "tf.Tensor([1 3], shape=(2,), dtype=int64)\n",
      "tf.Tensor([1 5], shape=(2,), dtype=int64)\n",
      "tf.Tensor([1 7], shape=(2,), dtype=int64)\n",
      "tf.Tensor([1 8], shape=(2,), dtype=int64)\n",
      "tf.Tensor([1 9], shape=(2,), dtype=int64)\n",
      "tf.Tensor([2 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor([2 2], shape=(2,), dtype=int64)\n",
      "tf.Tensor([2 3], shape=(2,), dtype=int64)\n",
      "tf.Tensor([2 4], shape=(2,), dtype=int64)\n",
      "tf.Tensor([2 7], shape=(2,), dtype=int64)\n",
      "tf.Tensor([2 8], shape=(2,), dtype=int64)\n",
      "tf.Tensor([3 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor([3 2], shape=(2,), dtype=int64)\n",
      "tf.Tensor([3 3], shape=(2,), dtype=int64)\n",
      "tf.Tensor([3 5], shape=(2,), dtype=int64)\n",
      "tf.Tensor([3 7], shape=(2,), dtype=int64)\n",
      "tf.Tensor([3 8], shape=(2,), dtype=int64)\n",
      "tf.Tensor([4 1], shape=(2,), dtype=int64)\n",
      "tf.Tensor([4 4], shape=(2,), dtype=int64)\n",
      "tf.Tensor([4 5], shape=(2,), dtype=int64)\n",
      "tf.Tensor([4 7], shape=(2,), dtype=int64)\n",
      "tf.Tensor([5 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor([5 2], shape=(2,), dtype=int64)\n",
      "tf.Tensor([5 3], shape=(2,), dtype=int64)\n",
      "tf.Tensor([5 5], shape=(2,), dtype=int64)\n",
      "tf.Tensor([5 6], shape=(2,), dtype=int64)\n",
      "tf.Tensor([6 1], shape=(2,), dtype=int64)\n",
      "tf.Tensor([6 2], shape=(2,), dtype=int64)\n",
      "tf.Tensor([6 4], shape=(2,), dtype=int64)\n",
      "tf.Tensor([6 5], shape=(2,), dtype=int64)\n",
      "tf.Tensor([6 7], shape=(2,), dtype=int64)\n",
      "tf.Tensor([6 8], shape=(2,), dtype=int64)\n",
      "tf.Tensor([6 9], shape=(2,), dtype=int64)\n",
      "tf.Tensor([7 2], shape=(2,), dtype=int64)\n",
      "tf.Tensor([7 4], shape=(2,), dtype=int64)\n",
      "tf.Tensor([7 6], shape=(2,), dtype=int64)\n",
      "tf.Tensor([7 7], shape=(2,), dtype=int64)\n",
      "tf.Tensor([7 8], shape=(2,), dtype=int64)\n",
      "tf.Tensor([7 9], shape=(2,), dtype=int64)\n",
      "tf.Tensor([8 1], shape=(2,), dtype=int64)\n",
      "tf.Tensor([8 2], shape=(2,), dtype=int64)\n",
      "tf.Tensor([8 3], shape=(2,), dtype=int64)\n",
      "tf.Tensor([8 7], shape=(2,), dtype=int64)\n",
      "tf.Tensor([8 8], shape=(2,), dtype=int64)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int64)\n",
      "tf.Tensor([9 1], shape=(2,), dtype=int64)\n",
      "tf.Tensor([9 4], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "88317d5f-e69b-4e88-9080-d5dc422a561f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseTensor(indices=tf.Tensor(\n",
       "[[0 0]\n",
       " [0 5]\n",
       " [0 8]\n",
       " [0 9]\n",
       " [1 0]\n",
       " [1 2]\n",
       " [1 3]\n",
       " [1 5]\n",
       " [1 7]\n",
       " [1 8]\n",
       " [1 9]\n",
       " [2 0]\n",
       " [2 2]\n",
       " [2 3]\n",
       " [2 4]\n",
       " [2 7]\n",
       " [2 8]\n",
       " [3 0]\n",
       " [3 2]\n",
       " [3 3]\n",
       " [3 5]\n",
       " [3 7]\n",
       " [3 8]\n",
       " [4 1]\n",
       " [4 4]\n",
       " [4 5]\n",
       " [4 7]\n",
       " [5 0]\n",
       " [5 2]\n",
       " [5 3]\n",
       " [5 5]\n",
       " [5 6]\n",
       " [6 1]\n",
       " [6 2]\n",
       " [6 4]\n",
       " [6 5]\n",
       " [6 7]\n",
       " [6 8]\n",
       " [6 9]\n",
       " [7 2]\n",
       " [7 4]\n",
       " [7 6]\n",
       " [7 7]\n",
       " [7 8]\n",
       " [7 9]\n",
       " [8 1]\n",
       " [8 2]\n",
       " [8 3]\n",
       " [8 7]\n",
       " [8 8]\n",
       " [8 9]\n",
       " [9 1]\n",
       " [9 4]], shape=(53, 2), dtype=int64), values=tf.Tensor(\n",
       "[ 2.  8.  1.  9.  9.  1.  5.  6.  3.  1. 10.  5.  4.  1.  1.  7.  1.  0.\n",
       "  3.  4. 10. 10.  8.  0.  0.  3.  3.  6. 10.  8. 10.  1.  9.  2. 10.  5.\n",
       "  0.  9.  0.  3. 10.  4.  8.  3.  8.  2.  4.  0.  9.  6.  7.  6.  1.], shape=(53,), dtype=float64), dense_shape=tf.Tensor([10 10], shape=(2,), dtype=int64))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(Z,tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d88bb0-a08b-417f-964c-baf019b607f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from typing import Union, TypeVar, Type\n",
    "import mpg.games.mpg as mpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf280984-dc52-4e08-bee7-8e1c088ea413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19 s ± 32.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9beecdae-9d4b-4867-9388-f652a8f535b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpg.graph.random_graph as rg\n",
    "G= rg.gnp_random_mpg(500,0.5,seed=27,distribution=\"integers\",low=-10,high=10,endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb3ac617-a83c-4c7d-ba9c-a5f937126a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.2 s ± 170 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mpg.optimal_strategy_pair(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d61f50ae-379f-43a3-80d6-94bb19c495b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664 ms ± 63.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import mpg.wrapper as wrapper\n",
    "%timeit wrapper.optimal_strategy_pair(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "25d92073-78bc-4e23-abd1-80a096a39347",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_winner(A,W,vertex,player):\n",
    "    edges = []\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(A.shape[1]):\n",
    "            if A[i,j] == 1:\n",
    "                edges.append((i,j,W[i,j]))\n",
    "    C=mpgwrapper.mpgcpp.winners_double_edges_cxx(edges)\n",
    "    return C[player][vertex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4b8d24e6-ff07-48b7-8aee-8ea2c59eae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_distribution: tfp.distributions.Distribution = tfp.distributions.Bernoulli(probs=0.57)\n",
    "d=tfp.distributions.Uniform(-10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9433860-4665-4ce3-a1c3-5b4d20b11c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
       "array([1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "698966d4-5293-40ed-bc43-40f4355d173b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x05\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes(tf.constant([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ae00552-cce2-4302-8e8b-ad6e76c62875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Graph 0:\n",
      "Processing Time 0.2986409664154053:\n",
      "Processing Graph 1:\n",
      "Processing Time 0.2029719352722168:\n",
      "Processing Graph 2:\n",
      "Processing Time 0.2950937747955322:\n",
      "Processing Graph 3:\n",
      "Processing Time 0.012552738189697266:\n",
      "Processing Graph 4:\n",
      "Processing Time 0.24564290046691895:\n",
      "Processing Graph 5:\n",
      "Processing Time 0.01729297637939453:\n",
      "Processing Graph 6:\n",
      "Processing Time 0.0193173885345459:\n",
      "Processing Graph 7:\n",
      "Processing Time 0.3035721778869629:\n",
      "Processing Graph 8:\n",
      "Processing Time 0.07518315315246582:\n",
      "Processing Graph 9:\n",
      "Processing Time 0.2042698860168457:\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import mpg.wrapper as mpgwrapper\n",
    "import time\n",
    "import mpg.graph.random_graph as rg\n",
    "times=[]\n",
    "for k in range(10):\n",
    "    G=rg.gnp_random_mpg(n=1000,p=0.001,distribution=\"normal\",loc=0,scale=1,loops=True)\n",
    "    print(f\"Processing Graph {k}:\",flush=True)\n",
    "    start=time.time()\n",
    "    mpgwrapper.mpgcpp.winners_float_edges_cxx([(int(u),int(v),int(G.edges[u,v][\"weight\"])) for u,v in G.edges])\n",
    "    end=time.time()\n",
    "    print(f\"Processing Time {end-start}:\",flush=True)\n",
    "    times.append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ed22b7-7140-40e3-bced-6bbceb834197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 17:21:21.398851: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Graph 0:\n",
      "Processing Time 0.1242368221282959:\n",
      "Processing Graph 1:\n",
      "Processing Time 0.015812397003173828:\n",
      "Processing Graph 2:\n",
      "Processing Time 0.016327857971191406:\n",
      "Processing Graph 3:\n",
      "Processing Time 0.01727604866027832:\n",
      "Processing Graph 4:\n",
      "Processing Time 0.016505002975463867:\n",
      "Processing Graph 5:\n",
      "Processing Time 0.01561427116394043:\n",
      "Processing Graph 6:\n",
      "Processing Time 0.018156051635742188:\n",
      "Processing Graph 7:\n",
      "Processing Time 0.01877140998840332:\n",
      "Processing Graph 8:\n",
      "Processing Time 0.01688218116760254:\n",
      "Processing Graph 9:\n",
      "Processing Time 0.013843297958374023:\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import mpg.wrapper as mpgwrapper\n",
    "import time\n",
    "import mpg.graph.random_graph as rg\n",
    "import numba\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mpg.graph.random_graph\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import tensorflow_probability as tfp\n",
    "import mpg.wrapper as mpgwrapper\n",
    "\n",
    "\n",
    "def _adj_matrix_generator(n,p):\n",
    "    \n",
    "    A=np.zeros([n,n],dtype=np.uint8)\n",
    "    for k in range(n):\n",
    "        A[k,:]=np.random.binomial(1,p,n)\n",
    "        while C.sum() == 0:\n",
    "            A[k,:]=np.random.binomial(1,p,n)\n",
    "    return A\n",
    "\n",
    "def _generate_dense_instances(n, p, seeder, cardinality: int, target: bool, weight_matrix: bool, flatten: bool,\n",
    "                              weight_distribution: tfp.distributions.Distribution, weight_type):\n",
    "    adjacency_distribution: tfp.distributions.Distribution = tfp.distributions.Bernoulli(probs=p,dtype=tf.bool)\n",
    "    turn_distribution: tfp.distributions.Distribution = tfp.distributions.Bernoulli(probs=0.5)\n",
    "    # discrete=tfp.distributions.DiscreteUniform(low=0,high=10)\n",
    "    shape = (n, n) if not flatten else (n * n,)\n",
    "    W = weight_distribution.sample(shape, seed=seeder())\n",
    "    dtype=weight_distribution.dtype\n",
    "    A=tf.numpy_function(_adj_matrix_generator,inp=[n,p],Tout=tf.uint8,stateful=False)\n",
    "    if flatten:\n",
    "        A=tf.reshape(A,shape=(-1,))\n",
    "    A = tf.cast(A,dtype=dtype)\n",
    "    W = tf.multiply(A, W)\n",
    "    vertex = tf.random.uniform((1,), 0, n, dtype=tf.int32, seed=seeder())\n",
    "    player = turn_distribution.sample((1,), seed=seeder())\n",
    "    if flatten:\n",
    "        if weight_matrix:\n",
    "            output = tf.concat(cast_all(dtype,A, W, vertex, player), axis=0)\n",
    "        else:\n",
    "            output = tf.concat(cast_all(dtype,A, vertex, player), axis=0)\n",
    "        if target:\n",
    "            if weight_type == tf.int32 or weight_type == tf.int64:\n",
    "                target_value = tf.py_function(\n",
    "                    lambda output: mpgwrapper.mpgcpp.winners_tensorflow_int_matrix_flattened_cxx(output.numpy().astype(np.int32).tolist()),\n",
    "                    inp=[output], Tout=tf.int32)\n",
    "            else:\n",
    "                target_value = tf.py_function(\n",
    "                    lambda output: mpgwrapper.mpgcpp.winners_tensorflow_float_matrix_flattened_cxx(output.numpy().astype(np.float32).tolist()),\n",
    "                    inp=[output], Tout=tf.float32)\n",
    "            target_value = tf.reshape(tf.ensure_shape(target_value, ()), shape=(1,))\n",
    "            return (tf.cast(output,dtype=tf.float32), tf.cast(target_value, dtype=tf.float32))\n",
    "        return output\n",
    "    else:\n",
    "        if weight_matrix:\n",
    "            output = tf.cast(tf.stack([A, W], axis=0), dtype=tf.float32)\n",
    "        else:\n",
    "            output = tf.cast(A, dtype=tf.float32)\n",
    "        if target:\n",
    "            return (output, tf.constant([vertex, player]), 1)\n",
    "        return (output, tf.constant([vertex, player]))\n",
    "\n",
    "\n",
    "def cast_all(dtype,*args):\n",
    "    return tuple(tf.cast(arg, dtype) for arg in args)\n",
    "times=[]\n",
    "with tf.device(\"/device:gpu:0\") as device:\n",
    "    for k in range(10):\n",
    "        print(f\"Processing Graph {k}:\",flush=True)\n",
    "        seeder=tfp.util.SeedStream(k,\"k\")\n",
    "        start=time.time()\n",
    "        _generate_dense_instances(n=200,p=1,seeder=seeder,cardinality=1,target=False,weight_matrix=True,flatten=True,weight_distribution=tfp.distributions.Uniform(-30,30),weight_type=\"int\")\n",
    "        end=time.time()\n",
    "        print(f\"Processing Time {end-start}:\",flush=True)\n",
    "        times.append(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8c2a788-4651-436e-b68a-bcd5003b3110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 0],\n",
       "       [1, 0, 1, ..., 1, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 1, 1],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 1, 0, 1],\n",
       "       [0, 0, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def _adj_matrix_generator(n,p):\n",
    "    A=np.zeros([n,n],dtype=np.uint8)\n",
    "    for k in range(n):\n",
    "        A[k,:]=np.random.binomial(1,p,n)\n",
    "        while A[k,:].sum() == 0:\n",
    "            A[k,:]=np.random.binomial(1,p,n)\n",
    "    return A\n",
    "_adj_matrix_generator(100,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdbe2ce-daac-41b5-83e2-59f25ff1196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "X=_generate_dense_instances(n=n,p=1,seeder=seeder,cardinality=1,\n",
    "                          target=False,weight_matrix=True,flatten=True,weight_distribution=tfp.distributions.Uniform(-30,30),weight_type=\"int\")\n",
    "L=[]\n",
    "Z=X.numpy()\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if Z[i+n*j] == 1:\n",
    "            L.append((i,j,int(Z[i+n*j+n*n])))\n",
    "a=time.time()\n",
    "mpgwrapper.mpgcpp.optimal_strategy_pair_edges_cxx(L)\n",
    "b=time.time()\n",
    "print(b-a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "677ae2a3-06e5-4f10-8f47-b5ab6beb52a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "L=[]\n",
    "Z=X.numpy()\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if Z[i+n*j] == 1:\n",
    "            L.append((i,j,int(Z[i+n*j+n*n])))\n",
    "print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "75ac754f-d0fd-4999-bfc3-48dfa4eec930",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "X=_generate_dense_instances(n=n,p=0.01,seeder=seeder,cardinality=1,\n",
    "                          target=False,weight_matrix=True,flatten=True,weight_distribution=tfp.distributions.Uniform(-30,30),weight_type=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "337ec9fa-baa7-4d6f-a0c2-6c2780218f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20002,), dtype=float32, numpy=array([ 0.,  0.,  0., ..., -0., 84.,  0.], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "023b2f1d-7806-4d08-84f7-ec466c1e43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z=X.numpy()\n",
    "Z=Z[n*n:2*n*n].reshape((n,n))\n",
    "Z=Z.astype(np.int32)\n",
    "Z\n",
    "A=X.numpy()[:n*n].reshape((n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1c25174-02f5-408f-be3d-87a357b34f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import mpg.games.mpg as mpg\n",
    "G=nx.from_numpy_array(A,create_using=mpg.MeanPayoffGraph)\n",
    "for e in G.edges:\n",
    "    u,v=e\n",
    "    G.edges[u,v][\"weight\"]=Z[u,v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "543a5ba9-1843-41f8-801a-df8b266ab095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 2.0,\n",
       "  1: 2.0,\n",
       "  2: 2.0,\n",
       "  3: -27.0,\n",
       "  4: 2.0,\n",
       "  5: 2.0,\n",
       "  6: -27.0,\n",
       "  7: -6.5,\n",
       "  8: 1.0,\n",
       "  9: 2.0,\n",
       "  10: 2.0,\n",
       "  11: 2.0,\n",
       "  12: 1.0,\n",
       "  13: 2.0,\n",
       "  14: 1.0,\n",
       "  15: 2.0,\n",
       "  16: -27.0,\n",
       "  17: 2.0,\n",
       "  18: 2.0,\n",
       "  19: 2.0,\n",
       "  20: 2.0,\n",
       "  21: 2.0,\n",
       "  22: 2.0,\n",
       "  23: 1.0,\n",
       "  24: 2.0,\n",
       "  25: -27.0,\n",
       "  26: 2.0,\n",
       "  27: 2.0,\n",
       "  28: 2.0,\n",
       "  29: 2.0,\n",
       "  30: 1.0,\n",
       "  31: 1.0,\n",
       "  32: 2.0,\n",
       "  33: 2.0,\n",
       "  34: 2.0,\n",
       "  35: -27.0,\n",
       "  36: 2.0,\n",
       "  37: 2.0,\n",
       "  38: 2.0,\n",
       "  39: 2.0,\n",
       "  40: -27.0,\n",
       "  41: -27.0,\n",
       "  42: 1.0,\n",
       "  43: 2.0,\n",
       "  44: -27.0,\n",
       "  45: 2.0,\n",
       "  46: 2.0,\n",
       "  47: 2.0,\n",
       "  48: 2.0,\n",
       "  49: 2.0,\n",
       "  50: 2.0,\n",
       "  51: 2.0,\n",
       "  52: -6.5,\n",
       "  53: 1.0,\n",
       "  54: 2.0,\n",
       "  55: 2.0,\n",
       "  56: 2.0,\n",
       "  57: 29.0,\n",
       "  58: -27.0,\n",
       "  59: 2.0,\n",
       "  60: -27.0,\n",
       "  61: 2.0,\n",
       "  62: 2.0,\n",
       "  63: 2.0,\n",
       "  64: 2.0,\n",
       "  65: -6.5,\n",
       "  66: 2.0,\n",
       "  67: 2.0,\n",
       "  68: 2.0,\n",
       "  69: 2.0,\n",
       "  70: 2.0,\n",
       "  71: 2.0,\n",
       "  72: 2.0,\n",
       "  73: -27.0,\n",
       "  74: 2.0,\n",
       "  75: -27.0,\n",
       "  76: -27.0,\n",
       "  77: 1.0,\n",
       "  78: 2.0,\n",
       "  79: 2.0,\n",
       "  80: 2.0,\n",
       "  81: 1.0,\n",
       "  82: 2.0,\n",
       "  83: -27.0,\n",
       "  84: 2.0,\n",
       "  85: 2.0,\n",
       "  86: 2.0,\n",
       "  87: 2.0,\n",
       "  88: 1.0,\n",
       "  89: -27.0,\n",
       "  90: 2.0,\n",
       "  91: -27.0,\n",
       "  92: -27.0,\n",
       "  93: 2.0,\n",
       "  94: 2.0,\n",
       "  95: -27.0,\n",
       "  96: -6.5,\n",
       "  97: 2.0,\n",
       "  98: 2.0,\n",
       "  99: 2.0},\n",
       " {0: 2.0,\n",
       "  1: 2.0,\n",
       "  2: 2.0,\n",
       "  3: -27.0,\n",
       "  4: 2.0,\n",
       "  5: -27.0,\n",
       "  6: -27.0,\n",
       "  7: 1.0,\n",
       "  8: -6.5,\n",
       "  9: 2.0,\n",
       "  10: 2.0,\n",
       "  11: 2.0,\n",
       "  12: 1.0,\n",
       "  13: -27.0,\n",
       "  14: -6.5,\n",
       "  15: 2.0,\n",
       "  16: 2.0,\n",
       "  17: 2.0,\n",
       "  18: -27.0,\n",
       "  19: -27.0,\n",
       "  20: -27.0,\n",
       "  21: 2.0,\n",
       "  22: 2.0,\n",
       "  23: 1.0,\n",
       "  24: 2.0,\n",
       "  25: -27.0,\n",
       "  26: -27.0,\n",
       "  27: -27.0,\n",
       "  28: 2.0,\n",
       "  29: 2.0,\n",
       "  30: 2.0,\n",
       "  31: -6.5,\n",
       "  32: -27.0,\n",
       "  33: 2.0,\n",
       "  34: -27.0,\n",
       "  35: 2.0,\n",
       "  36: 2.0,\n",
       "  37: 2.0,\n",
       "  38: -27.0,\n",
       "  39: 2.0,\n",
       "  40: -27.0,\n",
       "  41: -27.0,\n",
       "  42: -27.0,\n",
       "  43: 2.0,\n",
       "  44: 2.0,\n",
       "  45: 2.0,\n",
       "  46: 2.0,\n",
       "  47: 2.0,\n",
       "  48: 2.0,\n",
       "  49: 2.0,\n",
       "  50: 2.0,\n",
       "  51: 2.0,\n",
       "  52: 1.0,\n",
       "  53: 1.0,\n",
       "  54: 2.0,\n",
       "  55: 2.0,\n",
       "  56: 2.0,\n",
       "  57: 29.0,\n",
       "  58: -27.0,\n",
       "  59: 2.0,\n",
       "  60: 2.0,\n",
       "  61: 2.0,\n",
       "  62: 2.0,\n",
       "  63: 2.0,\n",
       "  64: 2.0,\n",
       "  65: 1.0,\n",
       "  66: 2.0,\n",
       "  67: 2.0,\n",
       "  68: 2.0,\n",
       "  69: 2.0,\n",
       "  70: 2.0,\n",
       "  71: -27.0,\n",
       "  72: -27.0,\n",
       "  73: 2.0,\n",
       "  74: 2.0,\n",
       "  75: 2.0,\n",
       "  76: 2.0,\n",
       "  77: 1.0,\n",
       "  78: -27.0,\n",
       "  79: -27.0,\n",
       "  80: 2.0,\n",
       "  81: 2.0,\n",
       "  82: 2.0,\n",
       "  83: 2.0,\n",
       "  84: 2.0,\n",
       "  85: 2.0,\n",
       "  86: 2.0,\n",
       "  87: 2.0,\n",
       "  88: -6.5,\n",
       "  89: 2.0,\n",
       "  90: 2.0,\n",
       "  91: 2.0,\n",
       "  92: -27.0,\n",
       "  93: 2.0,\n",
       "  94: 2.0,\n",
       "  95: 2.0,\n",
       "  96: 1.0,\n",
       "  97: -27.0,\n",
       "  98: 2.0,\n",
       "  99: 2.0})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpgwrapper.mean_payoffs(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc1cc7b5-9807-4ba8-a47e-aaef3cd5b606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " -2,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " -4,\n",
       " -5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " -1,\n",
       " -9,\n",
       " 4,\n",
       " 2,\n",
       " -6,\n",
       " 2,\n",
       " -5,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " -8,\n",
       " -1,\n",
       " 4,\n",
       " -3,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " -2,\n",
       " -8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " -1,\n",
       " 2,\n",
       " 5,\n",
       " -4,\n",
       " -1,\n",
       " -2,\n",
       " 1,\n",
       " 9,\n",
       " -9,\n",
       " -9,\n",
       " -8,\n",
       " 7,\n",
       " -9,\n",
       " -4,\n",
       " 8,\n",
       " -1,\n",
       " -1,\n",
       " -4,\n",
       " 9,\n",
       " -4,\n",
       " -8,\n",
       " -6,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " -3,\n",
       " -9,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " -2,\n",
       " -7,\n",
       " 4,\n",
       " 8,\n",
       " -7,\n",
       " -1,\n",
       " 3,\n",
       " 3,\n",
       " -9,\n",
       " -1,\n",
       " 8,\n",
       " -7,\n",
       " 6,\n",
       " -2,\n",
       " 3,\n",
       " -5,\n",
       " -9,\n",
       " -6,\n",
       " 2,\n",
       " -4,\n",
       " -1,\n",
       " -2,\n",
       " -8,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " -6,\n",
       " -1,\n",
       " -2,\n",
       " 2,\n",
       " -3,\n",
       " -8,\n",
       " 4,\n",
       " 1,\n",
       " -5,\n",
       " -9,\n",
       " 4,\n",
       " -9,\n",
       " -7,\n",
       " 9,\n",
       " 9,\n",
       " -6,\n",
       " 2,\n",
       " -6,\n",
       " -9,\n",
       " 5,\n",
       " 1,\n",
       " -8,\n",
       " 6,\n",
       " -6,\n",
       " -4,\n",
       " 3,\n",
       " 6,\n",
       " -6,\n",
       " 5,\n",
       " -9,\n",
       " 8,\n",
       " -1,\n",
       " -6,\n",
       " -4,\n",
       " -7,\n",
       " 5,\n",
       " 2,\n",
       " -4,\n",
       " -5,\n",
       " 9,\n",
       " 1,\n",
       " -4,\n",
       " 7,\n",
       " 7,\n",
       " -9,\n",
       " 8,\n",
       " 1,\n",
       " -6,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " -8,\n",
       " -8,\n",
       " 5,\n",
       " -3,\n",
       " 4,\n",
       " -9,\n",
       " 5,\n",
       " -5,\n",
       " 9,\n",
       " -6,\n",
       " -9,\n",
       " 6,\n",
       " 8,\n",
       " -1,\n",
       " 2,\n",
       " 2,\n",
       " -9,\n",
       " 2,\n",
       " -3,\n",
       " 9,\n",
       " -1,\n",
       " -6,\n",
       " 1,\n",
       " -6,\n",
       " -9,\n",
       " -2,\n",
       " 6,\n",
       " -1,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " -8,\n",
       " -5,\n",
       " 7,\n",
       " -4,\n",
       " -6,\n",
       " 8,\n",
       " -4,\n",
       " -7,\n",
       " -2,\n",
       " 1,\n",
       " -3,\n",
       " -3,\n",
       " -2,\n",
       " -9,\n",
       " 6,\n",
       " 8,\n",
       " -9,\n",
       " -2,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " -1,\n",
       " -1,\n",
       " -4,\n",
       " -9,\n",
       " 7,\n",
       " -4,\n",
       " -6,\n",
       " -2,\n",
       " -9,\n",
       " -9,\n",
       " -9,\n",
       " 2,\n",
       " 2,\n",
       " -6,\n",
       " -2,\n",
       " 7,\n",
       " -6,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " -5,\n",
       " 6,\n",
       " -1,\n",
       " 5,\n",
       " 2,\n",
       " -1,\n",
       " -3,\n",
       " 5,\n",
       " -1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " -2,\n",
       " 8,\n",
       " 3,\n",
       " -2,\n",
       " 7,\n",
       " -7,\n",
       " -7,\n",
       " 4,\n",
       " 9,\n",
       " -1,\n",
       " 6,\n",
       " -9,\n",
       " -3,\n",
       " 2,\n",
       " -8,\n",
       " -4,\n",
       " -8,\n",
       " 1,\n",
       " 6,\n",
       " -5,\n",
       " 6,\n",
       " 8,\n",
       " -4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " -3,\n",
       " -4,\n",
       " 5,\n",
       " -2,\n",
       " 5,\n",
       " 3,\n",
       " -1,\n",
       " -3,\n",
       " -1,\n",
       " -1,\n",
       " -9,\n",
       " -2,\n",
       " -3,\n",
       " 7,\n",
       " -5,\n",
       " -2,\n",
       " -2,\n",
       " -5,\n",
       " -4,\n",
       " -7,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " -5,\n",
       " -9,\n",
       " -5,\n",
       " 9,\n",
       " 8,\n",
       " -8,\n",
       " -5,\n",
       " -4,\n",
       " 1,\n",
       " -1,\n",
       " -5,\n",
       " 6,\n",
       " 8,\n",
       " -6,\n",
       " 9,\n",
       " 1,\n",
       " -9,\n",
       " -1,\n",
       " -1,\n",
       " -4,\n",
       " 3,\n",
       " 8,\n",
       " -7,\n",
       " -1,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " -8,\n",
       " 4,\n",
       " 3,\n",
       " -5,\n",
       " 1,\n",
       " -7,\n",
       " 8,\n",
       " -3,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " -6,\n",
       " 9,\n",
       " -6,\n",
       " 7,\n",
       " 3,\n",
       " -7,\n",
       " -8,\n",
       " -3,\n",
       " 8,\n",
       " -8,\n",
       " 7,\n",
       " -1,\n",
       " -8,\n",
       " -6,\n",
       " 2,\n",
       " -2,\n",
       " 4,\n",
       " -6,\n",
       " 9,\n",
       " -8,\n",
       " 1,\n",
       " -6,\n",
       " -7,\n",
       " -4,\n",
       " 7,\n",
       " 7,\n",
       " -1,\n",
       " -4,\n",
       " 7,\n",
       " -6,\n",
       " -1,\n",
       " 8,\n",
       " 7,\n",
       " -9,\n",
       " -8,\n",
       " 4,\n",
       " -3,\n",
       " 6,\n",
       " -8,\n",
       " 4,\n",
       " -2,\n",
       " -3,\n",
       " 3,\n",
       " -3,\n",
       " 3,\n",
       " -2,\n",
       " 5,\n",
       " -6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " -9,\n",
       " 5,\n",
       " -9,\n",
       " -6,\n",
       " -2,\n",
       " -7,\n",
       " -1,\n",
       " -3,\n",
       " -3,\n",
       " 9,\n",
       " -6,\n",
       " -7,\n",
       " -6,\n",
       " 2,\n",
       " -1,\n",
       " -9,\n",
       " -6,\n",
       " 7,\n",
       " -8,\n",
       " -1,\n",
       " 7,\n",
       " -5,\n",
       " 1,\n",
       " -9,\n",
       " 9,\n",
       " 3,\n",
       " -1,\n",
       " 4,\n",
       " -4,\n",
       " -4,\n",
       " 3,\n",
       " -8,\n",
       " 2,\n",
       " -2,\n",
       " 3,\n",
       " -4,\n",
       " -3,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " -2,\n",
       " -4,\n",
       " -8,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " -7,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " -3,\n",
       " -3,\n",
       " -7,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " -7,\n",
       " -1,\n",
       " -2,\n",
       " -3,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " -4,\n",
       " 1,\n",
       " 8,\n",
       " -4,\n",
       " -3,\n",
       " -1,\n",
       " -7,\n",
       " -4,\n",
       " 3,\n",
       " -2,\n",
       " -7,\n",
       " -4,\n",
       " 6,\n",
       " -4,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " -5,\n",
       " 1,\n",
       " 8,\n",
       " -3,\n",
       " -4,\n",
       " 1,\n",
       " -9,\n",
       " -6,\n",
       " -5,\n",
       " -7,\n",
       " -7,\n",
       " -1,\n",
       " -3,\n",
       " 3,\n",
       " -8,\n",
       " 1,\n",
       " -5,\n",
       " 8,\n",
       " -9,\n",
       " -1,\n",
       " -3,\n",
       " -6,\n",
       " -5,\n",
       " -2,\n",
       " -4,\n",
       " 9,\n",
       " -1,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " -1,\n",
       " 8,\n",
       " -1,\n",
       " -5,\n",
       " 3,\n",
       " -7,\n",
       " 9,\n",
       " -6,\n",
       " -3,\n",
       " -3,\n",
       " 6,\n",
       " -2,\n",
       " -2,\n",
       " -8,\n",
       " 8,\n",
       " -2,\n",
       " -9,\n",
       " -5,\n",
       " 5,\n",
       " -1,\n",
       " -3,\n",
       " 8,\n",
       " 2,\n",
       " -4,\n",
       " -3,\n",
       " 9,\n",
       " 3,\n",
       " -5,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " -6,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " -5,\n",
       " -8,\n",
       " 4,\n",
       " 6,\n",
       " -4,\n",
       " 7,\n",
       " -1,\n",
       " 6,\n",
       " -2,\n",
       " -9,\n",
       " -9,\n",
       " 6,\n",
       " -1,\n",
       " 1,\n",
       " 6,\n",
       " -8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " -5,\n",
       " 7,\n",
       " -8,\n",
       " 3,\n",
       " 8,\n",
       " -8,\n",
       " -2,\n",
       " 8,\n",
       " 4,\n",
       " -6,\n",
       " -9,\n",
       " -6,\n",
       " 4,\n",
       " -8,\n",
       " 6,\n",
       " 9,\n",
       " -7,\n",
       " -8,\n",
       " -4,\n",
       " 3,\n",
       " 2,\n",
       " -1,\n",
       " -8,\n",
       " 3,\n",
       " -1,\n",
       " 3,\n",
       " -6,\n",
       " -4,\n",
       " -2,\n",
       " 6,\n",
       " -6,\n",
       " -8,\n",
       " -1,\n",
       " -6,\n",
       " -8,\n",
       " 2,\n",
       " -6,\n",
       " -3,\n",
       " -5,\n",
       " -6,\n",
       " -9,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " -7,\n",
       " -6,\n",
       " -9,\n",
       " -1,\n",
       " 5,\n",
       " -5,\n",
       " -2,\n",
       " 5,\n",
       " -3,\n",
       " -9,\n",
       " 6,\n",
       " 3,\n",
       " -3,\n",
       " 6,\n",
       " -7,\n",
       " 3,\n",
       " -7,\n",
       " 1,\n",
       " -2,\n",
       " -9,\n",
       " 2,\n",
       " -3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " -1,\n",
       " -2,\n",
       " 1,\n",
       " -2,\n",
       " 9,\n",
       " -4,\n",
       " -8,\n",
       " -3,\n",
       " 4,\n",
       " -3,\n",
       " -1,\n",
       " 6,\n",
       " 3,\n",
       " -3,\n",
       " 6,\n",
       " -4,\n",
       " -2,\n",
       " 8,\n",
       " 4,\n",
       " -2,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " -1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " -8,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " -5,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " -1,\n",
       " -3,\n",
       " -4,\n",
       " -5,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " -9,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " -2,\n",
       " -3,\n",
       " 8,\n",
       " 2,\n",
       " -5,\n",
       " 8,\n",
       " 9,\n",
       " -1,\n",
       " -2,\n",
       " -2,\n",
       " 4,\n",
       " -8,\n",
       " -3,\n",
       " -8,\n",
       " 9,\n",
       " -7,\n",
       " -5,\n",
       " -5,\n",
       " -8,\n",
       " -7,\n",
       " 6,\n",
       " -5,\n",
       " 5,\n",
       " 6,\n",
       " -1,\n",
       " -7,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " -2,\n",
       " -8,\n",
       " -7,\n",
       " -8,\n",
       " 2,\n",
       " -4,\n",
       " -3,\n",
       " 8,\n",
       " -7,\n",
       " 6,\n",
       " -1,\n",
       " 2,\n",
       " -3,\n",
       " -4,\n",
       " -1,\n",
       " 8,\n",
       " 1,\n",
       " -1,\n",
       " 9,\n",
       " -9,\n",
       " -3,\n",
       " -3,\n",
       " -4,\n",
       " -8,\n",
       " -3,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " -1,\n",
       " 2,\n",
       " -7,\n",
       " -9,\n",
       " 5,\n",
       " -1,\n",
       " 4,\n",
       " -1,\n",
       " 1,\n",
       " -5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " -1,\n",
       " -2,\n",
       " -9,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " -3,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " -5,\n",
       " -8,\n",
       " -7,\n",
       " 8,\n",
       " 7,\n",
       " -1,\n",
       " -5,\n",
       " -3,\n",
       " 8,\n",
       " 8,\n",
       " -5,\n",
       " 3,\n",
       " -3,\n",
       " 1,\n",
       " -9,\n",
       " 1,\n",
       " 8,\n",
       " -6,\n",
       " -9,\n",
       " -4,\n",
       " -9,\n",
       " 2,\n",
       " 7,\n",
       " -3,\n",
       " 4,\n",
       " -4,\n",
       " 2,\n",
       " 1,\n",
       " -8,\n",
       " -2,\n",
       " -1,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " -9,\n",
       " 8,\n",
       " -8,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " -5,\n",
       " -6,\n",
       " 4,\n",
       " -2,\n",
       " -5,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " -4,\n",
       " -1,\n",
       " 8,\n",
       " -4,\n",
       " -3,\n",
       " -2,\n",
       " -3,\n",
       " -9,\n",
       " -7,\n",
       " 3,\n",
       " -7,\n",
       " 7,\n",
       " 6,\n",
       " -4,\n",
       " 3,\n",
       " -9,\n",
       " 8,\n",
       " -1,\n",
       " -8,\n",
       " -3,\n",
       " -2,\n",
       " 8,\n",
       " -3,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " -2,\n",
       " -2,\n",
       " 9,\n",
       " 4,\n",
       " -1,\n",
       " -7,\n",
       " -5,\n",
       " 4,\n",
       " -9,\n",
       " -9,\n",
       " 2,\n",
       " -1,\n",
       " -7,\n",
       " 6,\n",
       " -3,\n",
       " -6,\n",
       " -9,\n",
       " -5,\n",
       " -7,\n",
       " -6,\n",
       " -9,\n",
       " -7,\n",
       " -6,\n",
       " -6,\n",
       " -1,\n",
       " -1,\n",
       " 4,\n",
       " -4,\n",
       " -9,\n",
       " 8,\n",
       " -2,\n",
       " -5,\n",
       " -6,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " -2,\n",
       " -1,\n",
       " -9,\n",
       " 7,\n",
       " -1,\n",
       " -4,\n",
       " -8,\n",
       " -8,\n",
       " 3,\n",
       " -2,\n",
       " -6,\n",
       " 8,\n",
       " -5,\n",
       " 1,\n",
       " 5,\n",
       " -9,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " -5,\n",
       " -8,\n",
       " 7,\n",
       " -7,\n",
       " 8,\n",
       " 1,\n",
       " -2,\n",
       " -4,\n",
       " -5,\n",
       " -5,\n",
       " 2,\n",
       " -3,\n",
       " 1,\n",
       " -3,\n",
       " -2,\n",
       " 8,\n",
       " -9,\n",
       " 4,\n",
       " -7,\n",
       " -9,\n",
       " 1,\n",
       " -1,\n",
       " 6,\n",
       " -7,\n",
       " -5,\n",
       " -6,\n",
       " -7,\n",
       " -5,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " -7,\n",
       " -3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " -1,\n",
       " 9,\n",
       " -5,\n",
       " -1,\n",
       " 5,\n",
       " -3,\n",
       " 2,\n",
       " 4,\n",
       " -4,\n",
       " 8,\n",
       " -6,\n",
       " 2,\n",
       " 8,\n",
       " -7,\n",
       " -9,\n",
       " -2,\n",
       " 1,\n",
       " -4,\n",
       " -9,\n",
       " 6,\n",
       " -5,\n",
       " -7,\n",
       " 2,\n",
       " -1,\n",
       " 1,\n",
       " 3,\n",
       " -8,\n",
       " -6,\n",
       " 8,\n",
       " -9,\n",
       " 8,\n",
       " -6,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " -2,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " -8,\n",
       " 2,\n",
       " -2,\n",
       " -5,\n",
       " -1,\n",
       " -7,\n",
       " -1,\n",
       " -6,\n",
       " 8,\n",
       " -9,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " -1,\n",
       " 6,\n",
       " -2,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052c539-96f5-4dd5-a9de-4a5f4af6b4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
