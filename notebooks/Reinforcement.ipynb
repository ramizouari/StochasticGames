{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "1f188a3a-1a4a-4368-b2c4-1816a9e37719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:25.959745Z",
     "start_time": "2023-05-12T01:26:25.951790Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "074abc3c-371c-458e-9884-7360a4ec6be3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:27.488349Z",
     "start_time": "2023-05-12T01:26:27.479720Z"
    }
   },
   "outputs": [],
   "source": [
    "class CardGameEnv(py_environment.PyEnvironment):\n",
    "    def __init__(self):\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(), dtype=np.int32, minimum=0, maximum=1, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(1,), dtype=np.int32, minimum=0, name='observation')\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(np.array([self._state], dtype=np.int32))\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "        if self._episode_ended:\n",
    "          # The last action ended the episode. Ignore the current action and start\n",
    "          # a new episode.\n",
    "            return self.reset()\n",
    "\n",
    "        # Make sure episodes don't go on forever.\n",
    "        if action == 1:\n",
    "            self._episode_ended = True\n",
    "        elif action == 0:\n",
    "            new_card = np.random.randint(1, 11)\n",
    "            self._state += new_card\n",
    "        else:\n",
    "            raise ValueError('`action` should be 0 or 1.')\n",
    "\n",
    "        if self._episode_ended or self._state >= 21:\n",
    "            reward = self._state - 21 if self._state <= 21 else -21\n",
    "            return ts.termination(np.array([self._state], dtype=np.int32), reward)\n",
    "        else:\n",
    "            return ts.transition(\n",
    "              np.array([self._state], dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "f0e7220c-4d29-49b9-8302-02883cb6d20d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:28.521902Z",
     "start_time": "2023-05-12T01:26:28.503895Z"
    }
   },
   "outputs": [],
   "source": [
    "environment = CardGameEnv()\n",
    "utils.validate_py_environment(environment, episodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc71781-5bce-4538-bfda-a0a247e72ebe",
   "metadata": {},
   "source": [
    "## 2. MPG Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "99a08238-94c8-49c7-9ae6-619195e1bf8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:32.774105Z",
     "start_time": "2023-05-12T01:26:32.751900Z"
    }
   },
   "outputs": [],
   "source": [
    "from mpg.games import mpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "fe3b00ac-bf51-4eff-aef8-f1133467addf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:33.322302Z",
     "start_time": "2023-05-12T01:26:33.258487Z"
    }
   },
   "outputs": [],
   "source": [
    "from mpg.games import strategy,mpg\n",
    "from mpg.rl import model_free,environment as rl_env\n",
    "import importlib\n",
    "importlib.reload(strategy)\n",
    "importlib.reload(mpg)\n",
    "importlib.reload(model_free)\n",
    "importlib.reload(rl_env)\n",
    "G=mpg.mpg_from_file(\"data/test01.in\",ignore_header=1)\n",
    "G\n",
    "environment = rl_env.MPGEnvironment(G,0,0,10,bad_action_penalty=-40)\n",
    "utils.validate_py_environment(environment, episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "2bb6e23e-4fa9-4bec-80c5-49d34c162457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:34.202025Z",
     "start_time": "2023-05-12T01:26:34.167708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment.reward_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "69c18508-d3b6-41d1-93a0-bdb8f91e44c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:35.592708Z",
     "start_time": "2023-05-12T01:26:35.584564Z"
    }
   },
   "outputs": [],
   "source": [
    "environment = rl_env.MPGEnvironment(G,1,0,max_turns=100,bad_action_penalty=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "e7c5a12d-fc56-4a35-9581-9b48512b016c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:36.245614Z",
     "start_time": "2023-05-12T01:26:36.238562Z"
    }
   },
   "outputs": [],
   "source": [
    "fixed_env=rl_env.FixedStrategyMPGEnvironment(environment,strategy.GreedyStrategy(environment.graph,turn=mpg.MeanPayoffGraph.player1))\n",
    "fixed_env.reset()\n",
    "agent=model_free.RLearningAgent(fixed_env)\n",
    "fo_env=rl_env.FullyObservableMPGEnvironment(fixed_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f41ec1-eed2-4769-bb25-ed99ce012f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:37.707233Z",
     "start_time": "2023-05-12T01:26:37.693597Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51416da4-c2b4-4094-8be8-b7e3ba3b8cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:38.225562Z",
     "start_time": "2023-05-12T01:26:38.220705Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d73cbe-371d-4e71-a377-85152ad4009b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:38.851327Z",
     "start_time": "2023-05-12T01:26:38.842797Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa60ee-9a5f-4af3-8e9c-0a3a7e38f2e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:39.160058Z",
     "start_time": "2023-05-12T01:26:39.146655Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "3dfb546b-8732-4abc-8896-c321992e74b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:39.708070Z",
     "start_time": "2023-05-12T01:26:39.701952Z"
    }
   },
   "outputs": [],
   "source": [
    "environment._vertex=np.array(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "85b13569-779a-42dd-a437-8f48aa510c19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:42.240449Z",
     "start_time": "2023-05-12T01:26:42.230151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 5: 5, 3: 5, 4: 5}"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{1:2,5:5,3:5,4:5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "5d3abf8f-970a-44e6-962f-f35e7848b07e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:43.495649Z",
     "start_time": "2023-05-12T01:26:43.486393Z"
    }
   },
   "outputs": [],
   "source": [
    "A={0:np.zeros(5),1:np.zeros(5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "97bc5002-c85e-467c-8cd1-12520662e978",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:44.259762Z",
     "start_time": "2023-05-12T01:26:44.247105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "35401ede-5ea1-41ae-854d-523ac1fba58c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:51.584753Z",
     "start_time": "2023-05-12T01:26:51.550378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb7b596935f45f19fe0f43728619934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MPGVisualisation(layout=Layout(height='500px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpg.visualisation import game as vgame\n",
    "VG=vgame.MPGVisualisation(G)\n",
    "VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "48b7587a-d4d1-4aca-a8be-6ceb1bce0753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:52.423929Z",
     "start_time": "2023-05-12T01:26:52.405541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mpg.rl.architectures.example' from '/home/ramizouari/Academic/AI/MeanPayOffGames/notebooks/mpg/rl/architectures/example.py'>"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(rl_env)\n",
    "import mpg.rl.driver as rl_driver\n",
    "importlib.reload(rl_driver)\n",
    "import tf_agents as tfa\n",
    "import mpg.rl.replay_buffers as rl_replay\n",
    "importlib.reload(rl_replay)\n",
    "import mpg.rl.agents as rl_agents\n",
    "importlib.reload(rl_agents)\n",
    "import mpg.rl.architectures.example as rl_arch\n",
    "importlib.reload(rl_arch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "1c65aa2c-e06e-44cc-a71c-9369436afab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:53.217770Z",
     "start_time": "2023-05-12T01:26:53.173918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArraySpec(shape=(2, 8, 8), dtype=dtype('float32'), name=None)"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(rl_env)\n",
    "E=rl_env.MPGMatrixExtractor(matrix=\"both\",graph_size=8)\n",
    "E.get_env_specs(fixed_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "1d7bfa91-8c3b-43e2-9447-49cae8407420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:54.618005Z",
     "start_time": "2023-05-12T01:26:54.609786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  5.,  0.,  0.,  0.,  4.,  0.,  0.],\n",
       "        [ 0.,  0., -7.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  5.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [-3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0., -3.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.],\n",
       "        [ 5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]], dtype=float32)"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E(fixed_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "28758e61-549b-471f-af4c-49fc57c60701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:55.658355Z",
     "start_time": "2023-05-12T01:26:55.614671Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adam()\n",
    "\n",
    "converter=rl_env.MPGTrajectoryConverter(fixed_env,E)\n",
    "\n",
    "qnet=tfa.networks.q_network.QNetwork(\n",
    "    input_tensor_spec=converter.data_spec[\"environment\"],\n",
    "    action_spec=fixed_env.action_spec(),\n",
    "    preprocessing_layers=None,\n",
    "    preprocessing_combiner=None,\n",
    "    conv_layer_params=None,\n",
    "    fc_layer_params=(75, 40),\n",
    "    dropout_layer_params=None,\n",
    "    activation_fn=tf.keras.activations.relu,\n",
    "    kernel_initializer=None,\n",
    "    batch_squash=True,\n",
    "    dtype=tf.float32,\n",
    "    q_layer_activation_fn=None,\n",
    "    name='QNetwork'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f01eb4-acb2-457c-9726-7b3bca304136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:56.677655Z",
     "start_time": "2023-05-12T01:26:56.618413Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "6762ad1b-36bc-4bd4-a0d8-44b8abf18be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:57.578960Z",
     "start_time": "2023-05-12T01:26:57.559568Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RLearningAgent' object has no attribute 'training_data_spec'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[607], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_data_spec\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'RLearningAgent' object has no attribute 'training_data_spec'"
     ]
    }
   ],
   "source": [
    "agent.training_data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "c9f339bb-c1c1-49a2-b2ea-4309ead71cbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:58.099148Z",
     "start_time": "2023-05-12T01:26:58.092434Z"
    }
   },
   "outputs": [],
   "source": [
    "patched_agent=rl_agents.FullyObservableMPGAgentWrapper(agent,fixed_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c0a24b-f26d-4e12-a1f6-35736cac2919",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:58.549765Z",
     "start_time": "2023-05-12T01:26:58.544572Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "2f8f6c7b-aa44-4842-bb25-21140e6672ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:59.052599Z",
     "start_time": "2023-05-12T01:26:59.043391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'environment': TensorSpec(shape=(2, 8, 8), dtype=tf.float32, name='environment'),\n",
       "                 'state': BoundedTensorSpec(shape=(), dtype=tf.int32, name='observation', minimum=array(0, dtype=int32), maximum=array(7, dtype=int32))},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "dbbe210f-aba1-42af-9b45-2ef3d8500b36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:26:59.559488Z",
     "start_time": "2023-05-12T01:26:59.553975Z"
    }
   },
   "outputs": [],
   "source": [
    "#buffer=rl_replay.MPGMatrixBuffer(converter.data_spec[\"environment\"],10)\n",
    "train_env=tfa.environments.tf_py_environment.TFPyEnvironment(fo_env)\n",
    "T=tfa.specs.tensor_spec.add_outer_dims_nest(\n",
    "    train_env.time_step_spec(), [1]\n",
    ")\n",
    "A=tfa.specs.tensor_spec.add_outer_dims_nest(\n",
    "    train_env.action_spec(), [1]\n",
    ")\n",
    "O=tfa.specs.tensor_spec.add_outer_dims_nest(\n",
    "    train_env.observation_spec(), [1]\n",
    ")\n",
    "net=rl_arch.MPGNetworkExample(O,fo_env.count_vertices)\n",
    "agent=tfa.agents.DqnAgent(\n",
    "    time_step_spec=train_env.time_step_spec(),\n",
    "    action_spec= train_env.action_spec(),\n",
    "    q_network= net,\n",
    "    optimizer= optimizer,\n",
    "    observation_and_action_constraint_splitter= None,\n",
    "    epsilon_greedy= 0.1,\n",
    "    n_step_update = 2,\n",
    "#    training_data_spec= converter.data_spec\n",
    ")\n",
    "driver=rl_driver.MPGDriver(train_env,agent.collect_policy,total_observers=[],partial_observers=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "b9558aa8-671c-49bf-9707-088b1f6dedc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-12T01:34:39.768404Z",
     "start_time": "2023-05-12T01:31:01.615688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
       "  'observation': {'environment': <tf.Tensor: shape=(1, 2, 8, 8), dtype=float32, numpy=\n",
       " array([[[[ 0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "          [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.],\n",
       "          [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
       "          [ 0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.],\n",
       "          [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "         [[ 0.,  5.,  0.,  0.,  0.,  4.,  0.,  0.],\n",
       "          [ 0.,  0., -7.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  5.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [-3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  0.,  0., -3.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.,  3.,  0.,  0.,  0.],\n",
       "          [ 5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]], dtype=float32)>,\n",
       "                  'state': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([4], dtype=int32)>},\n",
       "  'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-96.], dtype=float32)>,\n",
       "  'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>}),\n",
       " ())"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import traceback\n",
    "driver.run(train_env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "f3aff162-250b-4ce3-abfc-49a70002aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=tfa.trajectories.time_step.TimeStep(step_type=np.array(tfa.trajectories.time_step.StepType.FIRST),observation=np.array(0),reward=np.array(0),discount=np.array(1))\n",
    "s=tfa.trajectories.PolicyStep(action=np.array(0))\n",
    "t1=tfa.trajectories.time_step.TimeStep(step_type=tfa.trajectories.time_step.StepType.FIRST,observation=np.array(0),reward=0,discount=1)\n",
    "#driver.observers[0](tfa.trajectories.from_transition(t0,s,t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "80ecb9d2-b1b4-4df0-b927-7b9e4661f6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': BoundedArraySpec(shape=(), dtype=dtype('int32'), name='observation', minimum=0, maximum=7),\n",
       " 'environment': ArraySpec(shape=(2, 8, 8), dtype=dtype('float32'), name='environment')}"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo_env.observation_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "d4ab7772-0da8-4eb5-8b86-099b94944f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': BoundedTensorSpec(shape=(), dtype=tf.int32, name='observation', minimum=array(0, dtype=int32), maximum=array(7, dtype=int32)),\n",
       " 'environment': TensorSpec(shape=(2, 8, 8), dtype=tf.float32, name='environment')}"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.observation_spec()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "21a5089e-0c72-4975-b0bc-e095dd441b67",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[272], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mbuffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mt1\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/stochastic_games/lib/python3.10/site-packages/tf_agents/replay_buffers/replay_buffer.py:83\u001B[0m, in \u001B[0;36mReplayBuffer.add_batch\u001B[0;34m(self, items)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21madd_batch\u001B[39m(\u001B[38;5;28mself\u001B[39m, items):\n\u001B[1;32m     73\u001B[0m   \u001B[38;5;124;03m\"\"\"Adds a batch of items to the replay buffer.\u001B[39;00m\n\u001B[1;32m     74\u001B[0m \n\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03m  Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;124;03m    Adds `items` to the replay buffer.\u001B[39;00m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m---> 83\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_add_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/stochastic_games/lib/python3.10/site-packages/tf_agents/replay_buffers/py_uniform_replay_buffer.py:100\u001B[0m, in \u001B[0;36mPyUniformReplayBuffer._add_batch\u001B[0;34m(self, items)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_add_batch\u001B[39m(\u001B[38;5;28mself\u001B[39m, items):\n\u001B[1;32m     99\u001B[0m   outer_shape \u001B[38;5;241m=\u001B[39m nest_utils\u001B[38;5;241m.\u001B[39mget_outer_array_shape(items, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_spec)\n\u001B[0;32m--> 100\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mouter_shape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPyUniformReplayBuffer only supports a batch \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    102\u001B[0m                               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msize of 1, but received `items` with batch \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    103\u001B[0m                               \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msize \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(outer_shape[\u001B[38;5;241m0\u001B[39m]))\n\u001B[1;32m    105\u001B[0m   item \u001B[38;5;241m=\u001B[39m nest_utils\u001B[38;5;241m.\u001B[39munbatch_nested_array(items)\n",
      "\u001B[0;31mIndexError\u001B[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "buffer.add_batch(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "fc2a9221-ff21-42fd-8b08-084ee9e69384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'environment': TensorSpec(shape=(2, 8, 8), dtype=tf.float32, name='environment'),\n",
       "                 'state': BoundedTensorSpec(shape=(), dtype=tf.int32, name='observation', minimum=array(0, dtype=int32), maximum=array(7, dtype=int32))},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.env.time_step_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7e0e3f7c-44bd-4215-9769-94e54f7793be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': ArraySpec(shape=(), dtype=dtype('int32'), name=None),\n",
       " 'environment': ArraySpec(shape=(2, 8, 8), dtype=dtype('float32'), name=None)}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer._data_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f73805c4-a91e-4e36-8e67-9b26065fbb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfa.utils.nest_utils.get_outer_array_shape(np.array([[5,3],[5,2]],dtype=np.int32),spec=tfa.specs.ArraySpec(shape=[2],dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "69bf8ddd-5709-47ce-be81-094ae576c361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array([1]),\n",
       " 'observation': array([0]),\n",
       " 'reward': array([0]),\n",
       " 'step_type': array([0], dtype=int32)})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "f24ca11d-2e3a-497d-94c2-33d8c5ba9e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
       " 'observation': {'environment': TensorSpec(shape=(2, 8, 8), dtype=tf.float32, name='environment'),\n",
       "                 'state': BoundedTensorSpec(shape=(), dtype=tf.int32, name='observation', minimum=array(0, dtype=int32), maximum=array(7, dtype=int32))},\n",
       " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
       " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6a242-ce25-4aba-911e-6e8960023333",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfa.utils.nest_utils.get_outer_array_shape(np.array([[5,3],[5,2]],dtype=np.int32),spec=tfa.specs.ArraySpec(shape=[2],dtype=np.int32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
