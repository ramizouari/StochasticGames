{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1f188a3a-1a4a-4368-b2c4-1816a9e37719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "074abc3c-371c-458e-9884-7360a4ec6be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardGameEnv(py_environment.PyEnvironment):\n",
    "    def __init__(self):\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(), dtype=np.int32, minimum=0, maximum=1, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(1,), dtype=np.int32, minimum=0, name='observation')\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "        return ts.restart(np.array([self._state], dtype=np.int32))\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "        if self._episode_ended:\n",
    "          # The last action ended the episode. Ignore the current action and start\n",
    "          # a new episode.\n",
    "            return self.reset()\n",
    "\n",
    "        # Make sure episodes don't go on forever.\n",
    "        if action == 1:\n",
    "            self._episode_ended = True\n",
    "        elif action == 0:\n",
    "            new_card = np.random.randint(1, 11)\n",
    "            self._state += new_card\n",
    "        else:\n",
    "            raise ValueError('`action` should be 0 or 1.')\n",
    "\n",
    "        if self._episode_ended or self._state >= 21:\n",
    "            reward = self._state - 21 if self._state <= 21 else -21\n",
    "            return ts.termination(np.array([self._state], dtype=np.int32), reward)\n",
    "        else:\n",
    "            return ts.transition(\n",
    "              np.array([self._state], dtype=np.int32), reward=0.0, discount=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f0e7220c-4d29-49b9-8302-02883cb6d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = CardGameEnv()\n",
    "utils.validate_py_environment(environment, episodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc71781-5bce-4538-bfda-a0a247e72ebe",
   "metadata": {},
   "source": [
    "## 2. MPG Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "99a08238-94c8-49c7-9ae6-619195e1bf8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpg.games.mpg.MeanPayoffGraph at 0x7f1e062a1fc0>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mpg.games import mpg\n",
    "G=mpg.mpg_from_file(\"data/test01.in\",ignore_header=1)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "fe3b00ac-bf51-4eff-aef8-f1133467addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpg.games import strategy,mpg\n",
    "from mpg.rl import model_free,environment as rl_env\n",
    "import importlib\n",
    "importlib.reload(strategy)\n",
    "importlib.reload(model_free)\n",
    "importlib.reload(rl_env)\n",
    "environment = rl_env.MPGEnvironment(G,0,0,10,bad_action_penalty=-40)\n",
    "utils.validate_py_environment(environment, episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb6e23e-4fa9-4bec-80c5-49d34c162457",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.reward_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "69c18508-d3b6-41d1-93a0-bdb8f91e44c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = rl_env.MPGEnvironment(G,1,0,max_turns=100,bad_action_penalty=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "e7c5a12d-fc56-4a35-9581-9b48512b016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_env=rl_env.FixedStrategyMPGEnvironment(environment,strategy.GreedyStrategy(environment.graph,turn=mpg.MeanPayoffGraph.player1))\n",
    "fixed_env.reset()\n",
    "agent=model_free.RLearningAgent(fixed_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "63d73cbe-371d-4e71-a377-85152ad4009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "6eaa60ee-9a5f-4af3-8e9c-0a3a7e38f2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.get_action(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3dfb546b-8732-4abc-8896-c321992e74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment._vertex=np.array(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "85b13569-779a-42dd-a437-8f48aa510c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2, 5: 5, 3: 5, 4: 5}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{1:2,5:5,3:5,4:5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "5d3abf8f-970a-44e6-962f-f35e7848b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A={0:np.zeros(5),1:np.zeros(5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "97bc5002-c85e-467c-8cd1-12520662e978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "35401ede-5ea1-41ae-854d-523ac1fba58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06af786e7ddc420fa538b69f2b3689ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MPGVisualisation(layout=Layout(height='500px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpg.visualisation import game as vgame\n",
    "VG=vgame.MPGVisualisation(G)\n",
    "VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7587a-d4d1-4aca-a8be-6ceb1bce0753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
