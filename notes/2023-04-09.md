## Installing CUDA
As the HPC alpha partition has a NVidia `GPU_NAME` supporting CUDA version 11.4, we have to install that particular version of CUDA.
To do that, we install cudatoolkit and cudnn:
```bash
conda install cudatoolkit=11.4 cudnn
```

After that, we will instal tensorflow 2.11 as follow:
```
pip install tensorflow=2.11
```

Finally, we must configure the environment so that TensorFlow will be able to use XLA and CUDA, we create a file `env_vars.sh`:
```bash
mkdir -p $CONDA_PREFIX/etc/conda/activate.d
touch $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh
```

We than populate it with the following content:
```bash
CUDNN_PATH=$(dirname $(python -c "import nvidia.cudnn;print(nvidia.cudnn.__file__)"))
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/:$CUDNN_PATH/lib
export XLA_FLAGS=--xla_gpu_cuda_data_dir=$CONDA_PREFIX
```


## 2. Creating Workspaces
We will create two workspaces.
The first is used to save the datasets, and the second will contain the runtime of the libraries.

### 2.1 Creating workspaces
This can be achieved as follow:
```bash
ws_allocate -F scratch -r 7 -m rami.zouari@mailbox.tu-dresden.de workspace 180
```
This will create a workspace following the `scratch` file system.

We will create the `dataset` workspace as follow:
```bash
ws_allocate -F scratch -r 7 -m rami.zouari@mailbox.tu-dresden.de dataset 180
```

Each workspace will be accessible via its path:
- We will save the path of the workspace path into the environment variable  `WORKSPACE`
- We will save the path of the datasets path into the environment variable  `WORKSPACE`

To ease their access, we will link them to the home directory via the following commands:
```bash
mkdir workspaces
ln -s $WORKSPACES worspaces/workspace
ln -s $DATASET workspaces/dataset
```

### 2.2 Configuring Runtime
On the workspace `WORKSPACE`, we  create a folder `conda` as follow:
```bash
mkdir $WORKSPACES/conda -p
```

We will create a conda environment as follow:
```bash
conda create --prefix $WORKSPACES/conda python=3.10
```

We will install the required packages, and in particular:
- `cudatoolkit=11.4`
- `cudatoolkit-dev`
- `cudnn`
- `tensorrt` (via pip)
These will add GPU support for the environment.

### 2.3 Configuring CUDA
Now, once cuda and tensorrt are both installed, we need to add both to the libraries path.

Also, if the installed TensorRT's version is greater than 8, we will add symbolic links that expose them also as version 7.
The latter is a hack, but should not pose any problem thanks to the guaranteed backward compatibility of TensorRT. (To verify this claim)

Finally, we will also need to add the path of `nvvm` to enable Linear Algebra Acceleration (XLA).

We propose the following script that will detect them automatically and add them 
```bash
CUDNN_PATH=$(dirname $(python -c "import nvidia.cudnn;print(nvidia.cudnn.__file__)"))
TENSORRT_PATH=$(dirname $(python -c "import tensorrt;print(tensorrt.__file__)"))
for file in $TENSORRT_PATH/*; do
        if [[ $file == *.8 ]]; then
                ln -fs $file "${file%8}7"
        fi
done
export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$TENSORRT_PATH:$CUDNN_PATH/lib:$LD_LIBRARY_PATH
export XLA_FLAGS=--xla_gpu_cuda_data_dir=$CONDA_PREFIX
```

This script will be included on the file  `$CONDA_PREFIX/etc/conda/activate.d/env_vars` so that it is sourced automatically when activating the anaconda environment.


## 3. Configuring Jupyter Lab
Since the Jupyter Notebook will be accessed remotely, it is highly recommended to set up a password, this can be done as following:

```bash
jupyter server password
```

We will create a folder `.secret` that will contain the certificates' secrets

We will also need to configure a certificate for the server. We will generate it as follow:
```bash
mkdir $HOME/.secret
openssl req -x509 -nodes -days 180 -newkey rsa:2048 -keyout $HOME/.secret/jupyter-key.key -out $HOME/.secret/jupyter-certificate.pem
```

The certificate field are populated as follow:
![[Pasted image 20230410023137.png]]

We will generate the configuration of jupyter via:
```bash
jupyter server --generate-config
```

Then we will set the port to something `32574`

Finally, we add the certificate and the private key to Jupyter's configuration by adding the following lines on `$HOME/.jupyter/jupyter_server_config.py`
```python
import os
SECRETS_FOLDER=os.path.join(os.getenv("HOME"), ".secret")
if SECRETS_FOLDER is None:
	raise RuntimeError("Unable to get HOME directory")
c.ServerApp.certfile = os.path.join(SECRETS_FOLDER,"jupyter-certificate.pem")
c.ServerApp.keyfile = os.path.join(SECRETS_FOLDER,"jupyter-key.key")
```

Finally, under `$HOME/.jupyter/jupyter_server_config.json`, we add the following:
```json
{
  "IdentityProvider": {
    "hashed_password": "SOME_ALREADY_GENERATED_HASHED_PASSWORD",
    "password_required": true
  }
}
```

## 4. Connection
We will connect to jupyter lab by defining establishing a tunneled connection:
```bash
ssh taurus.hrsk.tu-dresden.de -l razo743f -NL 8080:$COMPUTE_HOST:32574
```

Where `COMPUTE_HOST` is the environment variable defining the host of the compute node.
We can retrieve its value by running `ifconfig` on that machine.