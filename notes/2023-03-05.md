
## 1. Current Limitations:

### Optimal Strategy Pair
The minimum player's optimal strategy is an optimal max strategy on the dual graph. This may cause a problem if there is a strategy that gives a $0$ mean pay-off.

> It will be resolved if we declare $0$ mean pay-off as a tie. Should we do it?

If we instead apply a counter-strategy search, this will degrade the runtime.

### Mean Payoff
The calculation of the mean payoff may give a slight error. To verify

### Counter Strategy
- Floyd Warshall does not work as expected
- Bellman-Ford does only work on a game with a single source.

### Visualisation
- The colours should be also parameterizable at the constructor level

### Latex
The latex display of equations contains several inconsistencies regarding:
- Negative values: $5+-3$
- Zero: $4+0$

### Lack of Testing
We should add unit testing, integration testing to the project so that we can be more sure about the correctness of implementations

### Naming Conventions
We should choose naming conventions.


## 2. Considerations

### 2.1 Zero Mean Pay off

On the current definition, a $0$ mean-pay off results on a win for the first player. If we declare $0$ mean pay-off as a tie, then the game will be totally symmetric.

This is suitable for the machine learning model, as we will only learn one agent $\mathcal{A}$ for both players.maybe

The current definition requires an agent for each player.

On the other hand, this will cause the reduction to min-max to not give an optimal solution at some cases.

### 2.2 Generating Dataset
- Let $R$ be the targets. depending on the definition of the game, they are either:
	- P1/P2
	- P1/Tie/P2
- For $r\in R,$ let $N(r)$ the number of observations that has a target $r$
- We should generate a dataset such that:
	$$
	\forall p,q\in R,\quad N(p)\approx N(q)
	$$

We may require a super-computer for generating the dataset.


### 2.3 Dependence on the distribution
Clearly, the model will learn from a given distribution of graphs and weights.
- Should that be our objective?
- Should we try to make our model distirbution agnostic?

### 2.4 Working on $\mathbb{R}$
The current implementation works on $\mathbb{Z}$. It can be extended to $\mathbb{Q},$ may this transformation induces complexity bottlenecks. 

In fact, let $G=(V,E,L)$ be a mean pay-off game with rational weights.
Let $\frac{p(u,v)}{q(u,v)}$ be the irreducible representation of $L(u,v)$

The complexity of the algorithm will be:
$$
\DeclareMathOperator*{\LCM}{LCM}
\mathcal{O}\left(n\cdot \left(\LCM_{(u,v)\in E} q(u,v)\right)\cdot \left(\sum_{(u,v)\in E}p(u,v) \right)  \right)
$$

The machine learning agent should work on $\mathbb{R},$ and not in $\mathbb{Q}.$
And its runtime should not depend of the magnitude of $L$.


### 2.5 Importance of the problem
We should justify why this problem may be important to? (a layman person?)
