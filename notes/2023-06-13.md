
## 1. GNN
TensorFlow support an implementation of GNNs. Unfortunately, this is not support with the latest version as Tensoflow GNN still uses an old version of Protobuf.

We had to implement the GNN that supports weights layers manually.

## 2. Preprocessing Layers
Rework these layers.
Input should be in the form $(A,W)$ with:
- $A$ the adjacency matrix
- $W$ the weights matrix

## 3. Masked softmax

The masked softmax function is defined as:
$$
\text{msmax}(a,u)=\frac{a_ie^{u_i}}{\sum_{i=1}^n a_ie^{u_i}} = \frac{a\odot e^u}{a^T e^u}
$$

The gradient of this function is:
$$
\begin{align*}
\frac{\partial \text{msmax}}{\partial u_i}(u)_j&= \frac{a_i \delta_{i,j} e^{u_i}}{\sum_{k=1}^n a_ie^{u_k}} - \frac{a_{i}a_j e^{u_i}e^{u_j}}{\left(\sum_{k=1}^n a_ie^{u_k}\right)^2} \\
&=  \delta_{i,j} \text{msmax}(u)_j - \text{msmax}(u)_i \cdot \text{msmax}(u)_j \\
&= \text{msmax}(u)_j\cdot\left(\delta_{i,j}-\text{msmax}(u)_i\right) \\
\implies \frac{\partial \text{msmax}}{\partial u}(u)&=\text{diag}(\text{msmax}(u))-\text{msmax}(u)\text{msmax}(u)^T
\end{align*}
$$

We had to add the masked softmax to have a model that is equivariant under padding