
## 1. GNN
TensorFlow support an implementation of GNNs. Unfortunately, this is not support with the latest version as Tensoflow GNN still uses an old version of Protobuf.

We had to implement the GNN that supports weights layers manually.

## 2. Preprocessing Layers
Rework these layers.
Input should be in the form $(A,W)$ with:
- $A$ the adjacency matrix
- $W$ the weights matrix

## 3. Masked softmax

The masked softmax function is defined as:
$$
\text{msmax}(a,u)=\frac{a_ie^{u_i}}{\sum_{i=1}^n a_ie^{u_i}} = \frac{a\odot e^u}{a^T e^u}
$$

The gradient of this function is:
$$
\begin{align*}
\frac{\partial \text{msmax}}{\partial u_i}(u)_j&= \frac{a_i \delta_{i,j} e^{u_i}}{\sum_{k=1}^n a_ie^{u_k}} - \frac{a_{i}a_j e^{u_i}e^{u_j}}{\left(\sum_{k=1}^n a_ie^{u_k}\right)^2} \\
&=  \delta_{i,j} \text{msmax}(u)_j - \text{msmax}(u)_i \cdot \text{msmax}(u)_j \\
&= \text{msmax}(u)_j\cdot\left(\delta_{i,j}-\text{msmax}(u)_i\right) \\
\implies \frac{\partial \text{msmax}}{\partial u}(u)&=\text{diag}(\text{msmax}(u))-\text{msmax}(u)\text{msmax}(u)^T
\end{align*}
$$

We had to add the masked softmax to have a model that is equivariant under padding
No need to implement the gradient as the autograd supports the function `tf.fill`


## 4. Support for Ragged tensors
The model does support variable graph sizes.
Formally, the model support training and inference on any batch of size $(?,n ,n  , 2)\quad \forall n\in\mathbb{N}$

We want to go further, and allow ragged batches. That is a batch tensor $T_{b,i,j,k}$ where:
$$
\DeclareMathOperator{\shape}{shape}
\shape(T_{b}) =(n_b,n_b,2)\quad \text{for some} \space n_b\in \mathbb{N}
$$

The GNN model supports ragged batches, and can be enabled by setting `ragged_batches=true`.

Training on ragged batches is not supported on GPU as some functions required for the training still not implemented on the GPU on ragged tensors.

## 5. Refactoring Alpha Zero
We will implement two versions:
- A local version
- A version working on a cluster

The local version will be threaded. Thus we should ensure