\chapter{Model Design}

\section{Introduction}

\section{Objectives}
The main objective

\section{Properties}
We expect the model $\mathcal{M}$ to verify the following properties:

\subsection{Totality}
\subsubsection{Definition}
A function is total if it is defined in the whole domain.
\newline Also, we will say a model $\mathcal{M}$ is total if it works on all Mean Payoff Games..
\subsubsection{Importance}
This property implies two main characteristics:
\begin{enumerate}
	\item The model works for any Mean Payoff Game whatever the size of $\lvert \VertexSet \rvert.$ This is difficult to not violate, as most machine learning models require static shapes.
	\item The model works for any Mean Payoff Game whatever the representation is; This is implicitely verified by an encoding of the Mean Payoff Games.
\end{enumerate}

\subsection{Node Agnostic}
This property tells that a model should not use any extra information about the nodes.
\subsubsection{Formalisation}
Let $G_1(V_1,E_1,W_1,s_1),G_2(V_2,E_2,W_2,s_2)$ two equivalent Mean Payoff Games in the sense that there exists a bijection $\Phi:V_1\rightarrow V_2$ such that:
\begin{align*}
	E_2&=\{(\Phi(u),\Phi(v)),\quad (u,v)\in E_1\}\\
	\forall (u,v)\in E_1,\quad W_2(u,v)&=W_1(\Phi(u),\Phi(v)) \\
	s_2&= \Phi(s_1)
\end{align*}
Then:
$$
\Phi\left(\mathcal{M}(G_1)\right) = \mathcal{M}(G_2)
$$
\subsubsection{Explanation}
The property tells that if two graphs mean payoffs only differ by their node representation, then the results should also only differ by the representation of the nodes.
\subsubsection{Importance}
This property implies that we can simply encode a mean payoff as $G(V,E,W,s)$ as $G'(V',E',W',s')$ with  $V'=\{0,\dot,\lvert V \rvert-1\},$ and $E',W',s'$ defined accordingly.
\newline In fact, the encoding is done implicitely by our model\footnote{While the encoding is done implicitely, the model itself can violate this property. An example of this is a Multi Layer Perceptron. Which lead to different results for different encodings.}.

\subsection{Invariance under Positive Scaling}
This property comes directly from the fact that both the winner and the set of optimal strategies\footnote{Whatever the definition of optimality (Weak, Strong, Payoff).} are invariant under a positive scaling of the weights.
\newline
Now, it is very easy to make augment a model $\mathcal{M}$ into such invariant model $\mathcal{M}'.$ We only do the following:
$$
\mathcal{M}'(E,W,s)=\mathcal{M}'(E,\text{Normalize}(W),s)
$$
Where $\text{Normalize}$ is any endomorphism of weight functions that verify the following constraint:
$$
\forall_{\text{MPG}}G(E,W),\forall a\in\mathbb{R}_+^*,\quad \text{Normalize}(aW)=\text{Normalize}(W)
$$

\subsubsection{Standard Scaling}
This scaling treats the values of $W$ as samples of random variables, and divides $W$ by an estimate of their variance. 
\begin{align*}
	\text{Normalize}(W)&=\frac{W}{\sqrt{\mathbb{V}[W]}}\\
	\mathbb{V}[W]&=\frac{1}{\lvert E \rvert} \sum_{(u,v)\in E}(W(u,v)-\mathbb{E}[W])^2 \\
	\mathbb{E}[W]&=\frac{1}{\lvert E \rvert}\sum_{(u,v)\in E}W(u,v) 
\end{align*}



\subsubsection{Maximum Scaling}
This scaling reduces the interval of the weights to $[-1,1]$ by dividing by the largest weight in terms of absolute value:
$$
\text{Normalize}(W)=\frac{W}{\lVert W \rVert_{\infty}}
$$
\paragraph{Implementation Notes:}
The weights function is implemented as a matrix $W,$ which is equal to $0$ for $(u,v)\notin E.$ 
\newline It is important to igonre these zeros\footnote{And only these zeros. If $W(u,v)=0$ for $(u,v)\in E$, this term should be accounted.} in both normalisations, otherwise it may lead to biased scaling.

\subsection{Permutation Equivariance}
\subsubsection{Definition}
This property states that the model should ouptut the same results for permuted nodes, up to permutation of the results.
\subsubsection{Importance}
While it is a special case of the Node Agnostic property, but it is still important as the encoding of the graphs is done implicitely, and thus Permutation Equivariance is enough to get a Node Agnostic model.
\subsection{Stability under Padding}
\subsubsection{Definition}
Let $G_1(V_1,E_1,W_1,s_1),G_2(V_2,E_2,W_2,s_2)$ be two disjoint Mean Payoff Games, in the sense that $V_1\cap V_2=\varnothing.$
\newline The padding of $G_1$ by $G_2,$ denoted $G_1\rhd G_2$ defined as:
$$
G_1\rhd G_2=(V_1\cup V_2,E_1\cup E_2,W_1\cup W_2,s_1)
$$
A model is said to be stable under padding if:
$$
\mathcal{M}(G_1\rhd G_2)=\mathcal{M}(G_1)
$$
\subsubsection{Importance}
Deep Learning algorithms generally accept batches of data having a homogeneous shape.
\newline In the other hand, graph input generally has different shapes, and thus are problematic to most learning algorithms.
\newline While we succeeded in experimenting a learning algorithm with a ragged batch\footnote{A batch of inhomogeneous input}, it suffered the following limits:
\begin{itemize}
	\item It greatly limits the choice of potential models. 
	\item The training is not supported by GPU, as some core operations were only implemented in the CPU for ragged batches.
\end{itemize}
For this reasons, we opted to pad the graphs to get homogeneous batches, and this is why the stability under padding is important.
\subsubsection{Removing Unreachable Nodes}
Another major point for this property, is it gives the possibility to remove unreachable nodes\footnote{If we ignore the orientation. A stronger property allowing unreachable nodes on the di-graph can also be defined, but this is beyond the scope.} without affecting the model's results.

\section{Considered Models}

\section{Architectures}
\section{Augmentation using MCTS}