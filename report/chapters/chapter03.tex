\chapter{Model Design}
\label{section:ModelDesign}
\label{chapter:ModelDesign}

\section{Introduction}

\section{Objectives}
The main objective

\section{Properties}
\label{section:ModelDesign:Properties}
We expect the model $\mathcal{M}$ to verify the following properties:

\subsection{Totality}
\subsubsection{Definition}
A function is total if it is defined in the whole domain.
\newline Also, we will say a model $\mathcal{M}$ is total if it works on all Mean Payoff Games..
\subsubsection{Importance}
This property implies two main characteristics:
\begin{enumerate}
	\item The model works for any Mean Payoff Game whatever the size of $\lvert \VertexSet \rvert.$ This is tricky as most machine learning models act on a batch of data with a fixed shape.
	\item The model works for any Mean Payoff Game whatever the representation is; This is implicitely verified by an encoding of the Mean Payoff Games.
\end{enumerate}

\subsection{Node Agnostic}
This property tells that a model should not use any extra information about the nodes.
\subsubsection{Formalisation}
Let $G_1(V_1,E_1,W_1,s_1),G_2(V_2,E_2,W_2,s_2)$ two isomorphic Mean Payoff Games in the sense that there exists a bijection $\Phi:V_1\rightarrow V_2$ such that:
\begin{align*}
	E_2&=\{(\Phi(u),\Phi(v)),\quad (u,v)\in E_1\}\\
	\forall (u,v)\in E_1,\quad W_2(u,v)&=W_1(\Phi(u),\Phi(v)) \\
	s_2&= \Phi(s_1)
\end{align*}
Then:
$$
\Phi\left(\mathcal{M}(G_1)\right) = \mathcal{M}(G_2)
$$
\subsubsection{Explanation}
The property tells that if two graphs mean payoffs only differ by their node representation, then the results should also only differ by the representation of the nodes.

\subsubsection{Importance}
This property implies that we can simply encode a mean payoff as $G(V,E,W,s)$ as $G'(V',E',W',s')$ with  $V'=\{0,\dot,\lvert V \rvert-1\},$ and $E',W',s'$ defined accordingly.
\newline In fact, the encoding is done implicitely by our model\footnote{While the encoding is done implicitely, the model itself can violate this property. An example of this is a Multi Layer Perceptron. Which lead to different results for different encodings.}.

\begin{figure}[H]
	\begin{subfigure}[b]{0.3\textwidth}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,
			thick,main node/.style={circle,draw,font=\Large\bfseries}]
			\node[main node, fill=gray!50] (1) {$2$}; 
			\node[main node] (2) [right of =1] {$3$}; 
			\node[main node] (3) [above right of =1] {$0$}; 
			\node[main node] (4) [right of =2] {$1$}; 
			\path (1) edge [bend left] node {1} (3)
			edge [bend right] node [below] {-1} (2)
			(2) edge [bend right] node [above] {1} (1)
			edge [loop below] node {-1} (2)
			(3) edge [bend left] node {-5} (2)
			edge [bend left] node {-2} (4)
			(4) edge node {3} (2);
		\end{tikzpicture} 
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,
			thick,main node/.style={circle,draw,font=\Large\bfseries}]
			\node[main node, fill=gray!50] (1) {$0$}; 
			\node[main node] (2) [right of =1] {$1$}; 
			\node[main node] (3) [above right of =1] {$2$}; 
			\node[main node] (4) [right of =2] {$3$}; 
			\path (1) edge [bend left] node {1} (3)
			edge [bend right] node [below] {-1} (2)
			(2) edge [bend right] node [above] {1} (1)
			edge [loop below] node {-1} (2)
			(3) edge [bend left] node {-5} (2)
			edge [bend left] node {-2} (4)
			(4) edge node {3} (2);
		\end{tikzpicture}
	\end{subfigure} 
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,
			thick,main node/.style={circle,draw,font=\Large\bfseries}]
			\node[main node, fill=gray!50] (1) {\scriptsize Cat}; 
			\node[main node] (2) [right of =1] {\scriptsize Dog}; 
			\node[main node] (3) [above right of =1] {\small Yak}; 
			\node[main node] (4) [right of =2] {\scriptsize Fox}; 
			\path (1) edge [bend left] node {1} (3)
			edge [bend right] node [below] {-1} (2)
			(2) edge [bend right] node [above] {1} (1)
			edge [loop below] node {-1} (2)
			(3) edge [bend left] node {-5} (2)
			edge [bend left] node {-2} (4)
			(4) edge node {3} (2);
		\end{tikzpicture} 
	\end{subfigure}
	\caption{Three isomorphic Mean Payoff Games}
	\label{fig:NodeAgnostic}
\end{figure}
\FloatBarrier
In the figure \ref{fig:NodeAgnostic}, we have $3$ equivalent Mean Payoff Games.
To illustrate a node agnostic model:
\begin{itemize}
	\item Let $\mathcal{M}$ be a model that predicts for a given Mean Payoff Game, the action to be played at the starting node, and the winner.
	\item Suppose also that $\mathcal{M}(G_1)=(3,\text{Max})$
\end{itemize}
If $\mathcal{M}$ is node agnostic, then:
\begin{align*}
	\mathcal{M}(G_2)&=(1,\text{Max})\\
	\mathcal{M}(G_3)&=(\text{Dog},\text{Max})
\end{align*}
\subsection{Invariance under Positive Scaling}
\label{section:ModelDesign:Properties:Invariance}
This property comes directly from the fact that both the winner and the set of optimal strategies\footnote{Whatever the definition of optimality (Weak, Strong, Payoff).} are invariant under a positive scaling of the weights.
\newline
Now, it is very easy to make augment a model $\mathcal{M}$ into such invariant model $\mathcal{M}'.$ We only do the following:
$$
\mathcal{M}'(E,W,s)=\mathcal{M}'(E,\text{Normalize}(W),s)
$$
Where $\text{Normalize}$ is any endomorphism of weight functions that verify the following constraint:
$$
\forall_{\text{MPG}}G(E,W),\forall ,\quad \text{Normalize}(W)=\frac{W}{H(W)}
$$
With $H:\mathscr{F}(E,\mathbb{R})\rightarrow \mathscr{F}(E,\mathbb{R})$ a function satisfying\footnote{Special care must be when $H$ is $\ge$ instead of $>$}:
\begin{align*}
	\forall s\in\mathbb{R}_+^*,\quad H(sW)&=sH(W) \\
	H(W)&> 0
\end{align*}

\subsubsection{Standard Scaling}
This scaling treats the values of $W$ as samples of random variables, and divides $W$ by an estimate of their variance. 
\begin{align*}
	\text{Normalize}(W)&=\frac{W}{\sqrt{\mathbb{V}[W]}}\\
	\mathbb{V}[W]&=\frac{1}{\lvert E \rvert} \sum_{(u,v)\in E}(W(u,v)-\mathbb{E}[W])^2 \\
	\mathbb{E}[W]&=\frac{1}{\lvert E \rvert}\sum_{(u,v)\in E}W(u,v) 
\end{align*}



\subsubsection{Maximum Scaling}
This scaling reduces the interval of the weights to $[-1,1]$ by dividing by the largest weight in terms of absolute value:
$$
\text{Normalize}(W)=\frac{W}{\lVert W \rVert_{\infty}}
$$
\paragraph{Implementation Notes:}
The weights function is implemented as a matrix $W,$ which is equal to $0$ for $(u,v)\notin E.$ 
\newline It is important to igonre these zeros\footnote{And only these zeros. If $W(u,v)=0$ for $(u,v)\in E$, this term should be accounted.} in both normalisations, otherwise it may lead to biased scaling.

\begin{figure}[H]
	\begin{subfigure}[b]{0.45\textwidth}
		\raggedleft
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,
			thick,main node/.style={circle,draw,font=\Large\bfseries}]
			\node[main node, fill=gray!50] (1) {$2$}; 
			\node[main node] (2) [right of =1] {$3$}; 
			\node[main node] (3) [above right of =1] {$0$}; 
			\node[main node] (4) [right of =2] {$1$}; 
			\path (1) edge [bend left] node {1} (3)
			edge [bend right] node [below] {-1} (2)
			(2) edge [bend right] node [above] {1} (1)
			edge [loop below] node {-1} (2)
			(3) edge [bend left] node {-5} (2)
			edge [bend left] node {-2} (4)
			(4) edge node {3} (2);
		\end{tikzpicture} 
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.45\textwidth}
		\raggedright
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,
			thick,main node/.style={circle,draw,font=\Large\bfseries}]
			\node[main node, fill=gray!50] (1) {$2$}; 
			\node[main node] (2) [right of =1] {$3$}; 
			\node[main node] (3) [above right of =1] {$0$}; 
			\node[main node] (4) [right of =2] {$1$}; 
			\path (1) edge [bend left] node {0.2} (3)
			edge [bend right] node [below] {-0.2} (2)
			(2) edge [bend right] node [above] {0.2} (1)
			edge [loop below] node {-0.2} (2)
			(3) edge [bend left] node {-1} (2)
			edge [bend left] node {-0.4} (4)
			(4) edge node {0.6} (2);
		\end{tikzpicture} 
	\end{subfigure}
	\caption{Mean Payoff Game, with a rescaled version using Maximum normalization}
\end{figure}

\subsection{Permutation Equivariance}
\subsubsection{Definition}
This property states that the model should ouptut the same results for permuted nodes, up to permutation of the results.
\subsubsection{Importance}
While it is a special case of the Node Agnostic property, but it is still important as the encoding of the graphs is done implicitely, and thus Permutation Equivariance is enough to get a Node Agnostic model.
\subsection{Stability under Padding}
\label{section:Model:Properties:Scaling}
\subsubsection{Definition}
\begin{itemize}
	\item Let $G_1(V_1,E_1,W_1,s_1),G_2(V_2,E_2,W_2,s_2)$ be two disjoint Mean Payoff Games, in the sense that $V_1\cap V_2=\varnothing.$
	\item Let $B=(E_3,W_3)$ with $E_3\subseteq V_2\times V_1$ a bridge from $G_2$ to $G_1,$ and $W_3$ is the weight function of $E_3$
\end{itemize}
The padding of $G_1$ by $G_2$ using $B$ as a bridge, denoted as $G_1\overset{B}{\rhd} G_2$ is defined as:
$$
G_1\overset{B}{\rhd} G_2=(V_1\cup V_2,E_1\cup E_2 \cup E_3,W_1\cup W_2 \cup W_3,s_1)
$$
If the bridge $B$ is empty, in the sense that $E_3=\emptyset,$ then we denote we will simplify the notation to $G_1 \rhd G_2.$
\newline 
A model is said to be stable under padding if:
$$
\mathcal{M}(G_1\overset{B}{\rhd} G_2)=\mathcal{M}(G_1)
$$
\subsubsection{Importance}
Deep Learning algorithms generally accept batches of data having a homogeneous shape.
\newline In the other hand, graph input generally has different shapes, and thus are problematic to most learning algorithms.
\newline While we succeeded in experimenting a learning algorithm with a ragged batch\footnote{A batch of inhomogeneous input}, it suffered the following limits:
\begin{itemize}
	\item It greatly limits the choice of potential models. 
	\item The training is not supported by GPU, as some core operations were only implemented in the CPU for ragged batches.
\end{itemize}
For this reasons, we opted to pad the graphs to get homogeneous batches, and this is why the stability under padding is important.
\subsubsection{Removing Unreachable Nodes}
Another major point for this property, is it gives the possibility to remove unreachable nodes without affecting the model's results.
\begin{figure}[H]
	\begin{subfigure}[b]{0.45\textwidth}
		\raggedleft
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,
			thick,main node/.style={circle,draw,font=\Large\bfseries}]
			\node[main node, fill=gray!50] (1) {$2$}; 
			\node[main node] (2) [right of =1] {$3$}; 
			\node[main node] (3) [above right of =1] {$0$}; 
			\node[main node] (4) [right of =2] {$1$}; 
			
			\node[main node, fill=red!50] (7) [below of =2] {$6$}; 
			\node[main node, fill=red!50] (5) [below left of =7] {$4$}; 
			\node[main node, fill=red!50] (6) [below right of =7] {$5$}; 
			\path (1) edge [bend left] node {1} (3)
			edge [bend right] node [below] {-1} (2)
			(2) edge [bend right] node [above] {1} (1)
			edge [loop below] node {-1} (2)
			(3) edge [bend left] node {-5} (2)
			edge [bend left] node {-2} (4)
			(4) edge node {3} (2)
			(5) edge node {-3} (7)
			edge node {-2} (1)
			(6) edge node {5} (5)
			(7) edge node {0} (6)
			edge node {-5} (4);
		\end{tikzpicture} 
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.45\textwidth}
		\raggedright
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2cm,
			thick,main node/.style={circle,draw,font=\Large\bfseries}]
			\node[main node, fill=gray!50] (1) {$2$}; 
			\node[main node] (2) [right of =1] {$3$}; 
			\node[main node] (3) [above right of =1] {$0$}; 
			\node[main node] (4) [right of =2] {$1$}; 
			\path (1) edge [bend left] node {0.2} (3)
			edge [bend right] node [below] {-0.2} (2)
			(2) edge [bend right] node [above] {0.2} (1)
			edge [loop below] node {-0.2} (2)
			(3) edge [bend left] node {-1} (2)
			edge [bend left] node {-0.4} (4)
			(4) edge node {0.6} (2);
		\end{tikzpicture} 
	\end{subfigure}
	\caption{Mean Payoff Game before and after removing unreachable nodes}
	\label{fig:StableUnderPadding}
\end{figure}
\FloatBarrier
Following the example under figure \ref{fig:StableUnderPadding}, if the model $\mathcal{M}$ is stable under padding, then the vertices $\{4,5,6\}$ can be removed without affecting the results.
\newline In fact, this is true as the original mean payoff game can be constructed from the reduced one with a suitable padding.
\section{Considered Models}
While there are many possible predictive models. We considered mainly two families of predictive models.
\subsection{Value based Model}
Such model predicts the evaluation of a certain position.
\newline The evaluation is a function $\mathcal{M}:\VertexSet \times \PlayerSet \rightarrow [-1,1]$ with the following interpretation:
\begin{itemize}
	\item $\mathcal{M}(s,p)=1$ when the model predicts that player $p$ will win the game given the position.
	\item $\mathcal{M}(s,p)=-1$ whens the model predicts that player $p$ will lose the game given the position.
	\item $\mathcal{M}(s,p)=0$ when the model predicts that the position will result in a draw.
\end{itemize}
Now, while such a model can be used to predict the winner. We claim that it is not efficient\footnote{Efficient in the sense that we cannot extract the best strategy from the evaluation in linear time.} to extract the strategy from such model, as the information of winning alone does not directly induce a strategy.
\newline The following figure illustrates an example.
\begin{figure}
	\centering
	\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=4cm,
		thick,main node/.style={circle,draw,font=\Large\bfseries}]
		\node[main node] (5) {$5$};
		\node[main node, fill=gray!50] (1) [below left of =5] {$0$}; 
		\node[main node] (2) [below right of =5] {$1$}; 
		\node[main node] (3) [above right of =5] {$2$}; 
		\node[main node] (4) [above left of =5] {$3$}; 
		\path (1) edge [bend left=12] node {1} (5)
				  edge node {-1} (2)
		(2) edge node {-1} (3)
		edge [bend left=12] node {1} (5)
		(3) 
		edge [bend left=12] node {1} (5)
		edge node {-1} (4)
		(4)
		edge node {-1} (1)
		edge [bend left=12] node {1} (5)
		(5) edge [bend left=12] node {1} (1)
			edge [bend left=12] node {1} (2)
			edge [bend left=12] node {1} (3)
			edge [bend left=12] node {1} (4);
			
	\end{tikzpicture} 
	\caption{An MPG where the first player always wins.}
\end{figure}
\FloatBarrier
\subsection{Strategy based Model}
Such model predicts the strategy for each player.
\newline This is a function $\mathcal{M}:\VertexSet \times \PlayerSet \rightarrow \mathscr{P}(\VertexSet)$ such that:
\begin{align*}
	\forall (u,p)\in \VertexSet \times \PlayerSet, \quad \mathcal{M}(u,p) &\in \Adj u \\
	\forall (u,p) \in \VertexSet \times \PlayerSet,\forall v \in \Adj u, \quad  \mathcal{P}\left(\mathcal{M}(u,p) =v \right)  &\in [0,1] \\ 
\forall (u,p) \in \VertexSet \times \PlayerSet, \quad  \sum_{v\in \Adj u}\mathcal{P}\left(\mathcal{M}(u,p) =v \right) &=1 \\ 
\end{align*}
\section{Building the Model}
Our model follows from well esta../Figures/PreprocessingBlock.pngblished graph neural network architectures, with minor modifications to suit our needs.
\newline It is composed of blocks, each containing a \textbf{Weighted Graph Convolutional Network}.

\subsection{Preprocessing Block}
The preprocessing block is responsible to convert the graph to a format recognizable by the convolutional blocks.
\newline It takes the following steps:
\begin{enumerate}
	\item It takes a batch, add a padding to each graph so that the resulting batch is of homogenous shape.
	\item It adds some random edges to each graph, with some low probability \texttt{random\_connection\_probability}.
	\item It normalizes the weights.
	\item It adds some noise to the weights.
\end{enumerate} 

\subsubsection{Padding Layer}
First of all, we define $H_k$ be the graph of size $k$ in which all the edges are loops with $0$ as a weight. 
\newline Each graph $G^{(i)}=(A^{(i)},W^{(i)})$ in the batch has a size $r_i.$ 
\newline Let $r=\max_i r_i.$ The padding layer adds a potential padding to each graph in the following manner:
\begin{equation*}
	G^{(i)}\leftarrow G^{(i)} \rhd I_{r-r_i}
\end{equation*}
With that, the resulting batch will be of shape $(?,r,r,2)$
\subsubsection{Random Connections}
This layer adds an edge with some probability $p:$
\begin{equation*}
	A^{(i)}\leftarrow A^{(i)} \vee B^{(i)}
\end{equation*}
Where $B^{(i)}$ is a matrix of shape $(r,r)$ whose elements are sampled from the bernoulli distribution $\mathcal{B}(p)$.
\subsubsection{Weights Normalisation}
We want the model to be invariant under positive scaling. To achieve that, we implemented a weights normalization layer conforming to section \ref{section:Model:Properties:Scaling}
\subsubsection{Weights Noise}
For regularization, we implemented a weights noise layer, that adds a small additive noise to the weights, in the following manner:
\begin{equation*}
		W^{(i)}\leftarrow W^{(i)} + N^{(i)} \odot A^{(i)}
\end{equation*}
Where $N^{(i)}$ is the noise matrix. We implemented two kinds of noise:
\begin{itemize}
	\item Uniform noise, where each element of $N^{(i)}$ follows $\mathcal{U}(-r,r)$
	\item Gaussian noise, where each element of $N^{(i)}$ follows $\mathcal{N}(0,\sigma)$
\end{itemize}
Now, we should choose the noise small enough so that we do not change the winner of the mean payoff game, nor the optimal strategies.
\begin{theorem}
	For a Mean Payoff Game $G=(V,E,W,s,p),$ with integer weights. 
	\newline If $\lVert N\rVert_{\infty} < \frac{1}{2\lvert V \rvert}$, then $G$ and $G'=(V,E,W+N,s,p)$ have the same sets of $C_3$-optimal strategies for each player.
\end{theorem}
\begin{proof}
	Without loss of generality, we assume that $\Max$ wins.
	\newline Let $\Phi^{\Max}\in \mathtt{Optimal}(G,\Max)$ and $\Phi^{\Min}\in \mathtt{Optimal}(G,\Min)$ \newline Without a loss of generality, we assume that both $\Phi^{\Max},\Phi^{\Min}$ are positional.
	\newline Let $\mathcal{C}=(u_0,\dots,u_{m})$ the cycle of vertices induced by both strategies in $G.$ 
	\newline As $\Max$ wins, we have:
	\begin{equation*}
		v(G,\Phi^{\Max},\Phi^{\Min}) = \frac{1}{2m}\sum_{k=1}^{m}W(u_{k-1},u_{k}) > 0
	\end{equation*}
	As all the weights are integers, we have:
	\begin{equation*}
		\sum_{k=1}^{m}W(u_{k-1},u_{k}) \ge 1
	\end{equation*}
	With that, we conclude the follwing lower bound of the mean payoff:
	\begin{equation*}
		v(G,\Phi^{\Max},\Phi^{\Min}) \ge \frac{1}{m} \ge \frac{1}{2\lvert V \rvert} 
	\end{equation*}
	Finally, we show that $\Max$ is also winning in $G'$:
	\begin{align*}
		 v(G',\Phi^{\Max},\Phi^{\Min})  & \ge \frac{1}{2m}\sum_{k=1}^{m}W(u_{k-1},u_{k}) + N(u_{k-1},u_{k}) \\
		 &\ge v(G,\Phi^{\Max},\Phi^{\Min}) - \lVert N \rVert_{\infty} \\
		 & > 0
	\end{align*}
\end{proof}
This result gives the theoretical interval in which the noise will not change the optimal strategies in an integer Mean Payoff Game.
\newline In practice, as $N$ follows a symmetric distribution, the noise will tend to cancel itself, and the mean of the noise will tend to zero. 
\newline For that reason, we do believe that a noise $N\sim \mathcal{U}(-0.1,0.1)$ or $N\sim \mathcal{N}(0,0.1)$ will keep the winners and strategies intact for most generated mean payoff games\footnote{Even for mean payoff games with real weights, we do believe that the same applies for weights following the distribution $\mathcal{U}(-1,1)$.}.
\subsubsection{One Hot Encoding}
The one hot encoding layer, as its name suggests, applies one hot encoding to the position $s.$


\begin{figure}[H]
	\noindent
	
	\makebox[\textwidth]{\includegraphics[width=1.2\textwidth]{Figures/PreprocessingBlock.png}}
	\caption{Preprocessing Block}
	\label{fig:PreprocessingBlock}
\end{figure}
\newpage

\subsection{Weighted Graph Convolutional Network}
The weighted graph convolutional network \textbf{WGCN}, as its name suggests, is a convolutional operator acting on graphs, with many desirable properties such as ``Permutation Equivariance" and ``Stability under Padding".
\newline It is based on the graph convolutional network as described on the following figure
\begin{figure}[H]
	\noindent
	
	\makebox[\textwidth]{\includegraphics[width=1.2\textwidth]{Figures/GCN.png}}
	\caption{Graph Convolutional Network}
	\label{fig:GCN}
\end{figure}
\FloatBarrier
Here $\oslash$ denotes the point-wise division operator.
\newline 
The problem with \textbf{GCN} is that they ignore the weights information. For Mean Payoff Games, such information is crucial to determine the winner and the strategies.
\newline For that, we introduced \textbf{WGCN} to capitalize on the weights information. The figure below shows how it is implemented.

\begin{figure}[H]
	\noindent
	
	\makebox[\textwidth]{\includegraphics[width=1.2\textwidth]{Figures/WGCN.png}}
	\caption{Weighted Graph Convolutional Network \label{fig:WGCN}}
\end{figure}
\FloatBarrier
The \textbf{WGCN} operator exhibits the desired properties described on \ref{section:ModelDesign:Properties}, except property  \ref{section:ModelDesign:Properties:Invariance}, the latter is already verified as a result of the preprocessing layer.
\newline We were not able to find a reference to \textbf{WGCN} in the literature. The closest thing we have found that a PyTorch based GNN library named \textbf{Geometric} has an implementation for \textbf{GCN} supporting weighted graphs. Interestingly, we only differ to them by the normalization of the degrees.
\newline As we are using \textit{TensorFlow}, we cannot use their approach, so we had to implement \textbf{WGCN} from scratch.

\subsection{Convolutional Block}
Each intermediate block is composed of a graph convolution, and then a batch normalisation operator, as described by the figure below:
\begin{figure}[H]
	\noindent
	
	\makebox[\textwidth]{\includegraphics[width=1.2\textwidth]{Figures/ConvolutionalBlock.png}}
	\caption{Graph Convolutional Block}
	\label{fig:ConvolutionalBlock}
\end{figure}
\FloatBarrier
This block was inspired from convolutional blocks used in computer vision models.
\subsection{Prediction Block}
\begin{figure}[H]
	\noindent
	
	\makebox[\textwidth]{\includegraphics[width=1.2\textwidth]{Figures/PredictionBlock.png}}
	\caption{Graph Convolutional Block}
	\label{fig:PredictionBlock}
\end{figure}
\FloatBarrier
\subsection{Model Architecture}
Putting all building block together, we designed a model that takes arbitrary graphs, encode them, predicts the strategy and the evaluation of the position.
\newline We were very careful in the design so that we can verify all the desired properties described in section \ref{section:ModelDesign:Properties}.
\newline The figure below shows the whole architecture:

\begin{landscape}

	\begin{figure}[H]
	\centering
		
		{\includegraphics[height=0.93\textheight]{Figures/Architecture.png}}
		\caption{Model Architecture}
		\label{fig:ModelArchitecture}
	\end{figure}
	
\end{landscape}

\section{Optimization}
Once we built the model architecture, we have to define the optimization problem to refine the learnable parameters.

Also, there is a wide range of optimizers that we can use. The next two sections will respectfully define the loss function and the optimizer.
\subsection{Loss function}
\begin{itemize}
	\item Let $\boldsymbol{G}$ be a batch of \acrshortpl{mpg}.
	\item Let $\boldsymbol{v}$ be a batch of evaluations of $\boldsymbol{G}$ 
	\item Let $\boldsymbol{\Pi}$ be a batch of strategies of $\boldsymbol{G}$
	\item Let $\mathcal{M}_{\Theta}$ be the model with $\Theta$ the learnable parameters.
	\item Let $\boldsymbol{v}_{\Theta}$ be the predicted evaluation per model $\mathcal{M}_{\Theta}$
	\item Let $\boldsymbol{\Pi}_{\Theta}$ be the predicted strategy per model $\mathcal{M}_{\Theta}$ 
	\item Let $\mathcal{H}$ be the categorical cross entroy operator defined as follow:
	\begin{equation*}
		\mathcal{H}(p,q) = \sum_{i}p_i \log q_i 
	\end{equation*}
\end{itemize}
We defined the loss function similar to Alpha Zero's approach \cite{AlphaZero}:
\begin{equation}
	\label{eqn:LossFunction}
	\mathcal{L}(\mathcal{M}_{\Theta},\boldsymbol{G},\boldsymbol{v},\boldsymbol{\Pi}) = \mathcal{H}(\boldsymbol{\Pi},\boldsymbol{\Pi}_\Theta(\boldsymbol{G})) + \lVert \boldsymbol{v}_{\Theta}(\boldsymbol{G})- \boldsymbol{v} \rVert_2^2 +  C \lVert \Theta \rVert_2^2
\end{equation}
This is the sum of three terms:
\begin{itemize}
	\item $\displaystyle \mathcal{H}(\boldsymbol{\Pi},\boldsymbol{\Pi}_\Theta(\boldsymbol{G})):$ This term encodes the error between the predicted strategy $\boldsymbol{\Pi}_\Theta(\boldsymbol{G})$ and the actual strategy $\boldsymbol{\Pi}$.
	\item $\displaystyle \lVert \boldsymbol{v}_{\Theta}(\boldsymbol{G})- \boldsymbol{v} \rVert_2^2:$ This term encodes the euclidean distance between the predicted evaluation $\boldsymbol{v}_{\Theta}(\boldsymbol{G})$ and the actual evaluation $\boldsymbol{v}$.
	\item $\displaystyle C \lVert \Theta \rVert_2^2$ This term adds $\mathscr{L}^2$ regularization to the model, with $C$ serving as the strength of the regularization.
\end{itemize}
Also, each error term in the loss function is applied to each game individually. In fact, equation \eqref{eqn:LossFunction} is in a compact representation that reduces\footnote{Up to some normalization factor, this is an implementation detail.} to the mean of individual errors in the batch.
\subsection{Optimizer}
We used the Adam\footnote{Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.} optimizer \cite{AdamOptimizer} to minimize the objective function $\mathcal{L}$ with respect to $\Theta$

\subsection{Hyper-parameters}
Our choice of optimizer and loss function induced more hyper-parameters. We will list them in the following table:
\begin{table}[h]
	\begin{tabularx}{\textwidth}{| X | X | X | X |}
		\hline
		Hyper-parameter & Symbol & Default value &  Description \\ 
		\hline
		\texttt{learning\_rate} & $\mu$ & $10^{-3}$ & The step size of the gradient descent method \\ 
		\hline
		\texttt{beta\_1} & $\beta_1$ & $0.9$ & The exponential decay rate for the $1^\text{st}$ moment estimates. \\ 
		\hline
		\texttt{beta\_2} & $\beta_2$ & $0.999$ & The exponential decay rate for the $2^\text{nd}$ moment estimates. \\ 
		\hline
		\texttt{epsilon} & $\hat{\varepsilon}$ & $10^{-7}$ & A small additive constant used for numerical stability. \\
		\hline
		\texttt{weight\_decay} & $C$ & $10^{-4}$ & The strength of the $\mathscr{L}^2$ regularization. \\
		\hline
	\end{tabularx}
	\caption{Le tableau d'avancement des BNNs
		\label{table:OptimizerHyperparameters}}
\end{table}

\section{Configuration}
\label{section:ModelDesign:Configuration}
we externalized our configuration so that we can change hyper-parameters and other non-learnable parameters at will, without modifying the source code. This was beneficial as it seperated between the model implementation phase and the model fine-tuning phase.
\subsection{Model configuration}
We setup a configuration \acrshort{yaml} configuration file containing the entries for tweaking the model.
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.95\textwidth]{Figures/ModelConfiguration.png}
	\caption{Model section of the configuration file \label{fig:ModelConfiguration}}
	\small{Note: while a recent version of the configuration file, we may tweak it further for fine-tuning purposes.}
\end{figure}
\FloatBarrier
\subsection{Training configuration}
The configuration file also has a section for training hyper-parameters. We will show it in the next figure:
\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\textwidth]{Figures/TrainingConfiguration.png}
	\caption{Training section of the configuration file\label{fig:TrainingConfiguration}}
	\small{Note: while a recent version of the configuration file, we may tweak it further for fine-tuning purposes.}
\end{figure}