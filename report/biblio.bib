@comment{x-kbibtex-encoding=utf-8}

@article{MCTS,
	author = {Maciej Świechowski and Konrad Godlewski and Bartosz Sawicki and Jacek Mańdziuk},
	doi = {10.1007/s10462-022-10228-y},
	journal = {Artificial Intelligence Review},
	month = {jul},
	number = {3},
	pages = {2497–2562},
	publisher = {Springer Science and Business Media {LLC} },
	title = {Monte Carlo Tree Search: a review of recent modifications and applications},
	url = {https://doi.org/10.1007%2Fs10462-022-10228-y},
	volume = {56},
	year = 2022
}

@article{PositionalStrategies,
	abstract = {We study some games of perfect information in which two players move alternately along the edges of a finite directed graph with weights attached to its edges. One of them wants to maximize and the other to minimize some means of the encountered weights.},
	address = {DEU},
	author = {A. Ehrenfeucht and J. Mycielski},
	doi = {10.1007/BF01768705},
	issn = {0020-7276},
	issue_date = {Jun 1979},
	journal = {Int. J. Game Theory},
	keywords = {Game Theory, Directed Graph, Positional Strategy, Perfect Information, Economic Theory},
	month = {jun},
	number = {2},
	numpages = {5},
	pages = {109–113},
	publisher = {Physica-Verlag GmbH},
	title = {Positional Strategies for Mean Payoff Games},
	url = {https://doi.org/10.1007/BF01768705},
	volume = {8},
	year = {1979}
}

@misc{TropicalCSP,
	archiveprefix = {arXiv},
	author = {Manuel Bodirsky and Marcello Mamino},
	eprint = {1506.04184},
	primaryclass = {cs.CC},
	title = {Tropically convex constraint satisfaction},
	year = {2017}
}

@inbook{AverageTimeRewardStochastic,
	abstract = {In this paper we give a general representation for a projection in terms of its range and the range of its adjoint projection. By combining this representation with recent results of the author on the structure of the algebraic eigenspace of a nonnegative matrix corresponding to its spectral radius, we develop a computational method to find the cigenprojection of a nonnegative matrix at its spectral radius. The results are illustrated by giving a closed formula for computing the limiting matrix of a stochastic matrix.},
	address = {Berlin, Heidelberg},
	author = {G. Rothblum},
	booktitle = {Stochastic Systems: Modeling, Identification and Optimization, II},
	doi = {10.1007/BFb0120751},
	editor = {Roger J.- B. Wets},
	isbn = {978-3-642-00786-6},
	pages = {188–201},
	publisher = {Springer Berlin Heidelberg},
	title = {Computation of the eigenprojection of a nonnegative matrix at its spectral radius},
	url = {https://doi.org/10.1007/BFb0120751},
	year = {1976}
}

@misc{DeepLearningHistory,
	author = {{Tim Dettmers}},
	howpublished = {\url{https://developer.nvidia.com/blog/deep-learning-nutshell-history-training/}},
	title = {Deep Learning in a Nutshell: History and Training},
	year = {16 Dec. 2015}
}

@book{FirstDeepNN,
	author = {A.G. Ivakhnenko and V.G. Lapa and V.G. Lapa and R.N. McDonough},
	isbn = {9780444000200},
	lccn = {67027815},
	publisher = {American Elsevier Publishing Company},
	series = {Modern analytic and computational methods in science and mathematics},
	title = {Cybernetics and Forecasting Techniques},
	url = {https://books.google.tn/books?id=rGFgAAAAMAAJ},
	year = {1967}
}

@article{LeNet,
	author = {Y. Lecun and L. Bottou and Y. Bengio and P. Haffner},
	doi = {10.1109/5.726791},
	journal = {Proceedings of the IEEE},
	number = {11},
	pages = {2278–2324},
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	year = {1998}
}

@article{OriginalSVM,
	author = {Corinna Cortes and Vladimir Vapnik},
	journal = {Machine learning},
	number = {3},
	pages = {273–297},
	publisher = {Springer},
	title = {Support-vector networks},
	volume = {20},
	year = {1995}
}

@article{BNNReview,
	author = {Chunyu Yuan and Sos S. Agaian},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-2110-06804.bib},
	eprint = {2110.06804},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Fri, 22 Oct 2021 13:33:09 +0200},
	title = {A comprehensive review of Binary Neural Network},
	url = {https://arxiv.org/abs/2110.06804},
	volume = {abs/2110.06804},
	year = {2021}
}

@misc{ShrinkingDeepLearningCarbon,
	author = {Kim Martineau},
	title = {Shrinking deep learning’s carbon footprint},
	url = {https://news.mit.edu/2020/shrinking-deep-learning-carbon-footprint-0807},
	year = {07 Aug 2021}
}

@misc{HouseCarbonFootprint,
	author = {Citu Group},
	title = {What is the carbon footprint of a house?},
	url = {https://citu.co.uk/citu-live/what-is-the-carbon-footprint-of-a-house}
}

@misc{LeeSedolVsAlphaGo,
	author = {Melissa Chan},
	title = {Go Player Finally Defeats Google’s AlphaGo After 3 Losses},
	url = {https://time.com/4257406/go-google-alphago-lee-sedol},
	year = {14 Mar 2016}
}

@article{CO2Footprint,
	author = {Emma Strubell and Ananya Ganesh and Andrew McCallum},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1906-02243.bib},
	eprint = {1906.02243},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Thu, 13 Jun 2019 13:36:00 +0200},
	title = {Energy and Policy Considerations for Deep Learning in {NLP}},
	url = {http://arxiv.org/abs/1906.02243},
	volume = {abs/1906.02243},
	year = {2019}
}

@article{BNNDefinition,
	author = {Chunyu Yuan and Sos S. Agaian},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-2110-06804.bib},
	eprint = {2110.06804},
	eprinttype = {arXiv},
	journal = {CoRR},
	pages = {3–4},
	timestamp = {Fri, 22 Oct 2021 13:33:09 +0200},
	title = {A comprehensive review of Binary Neural Network},
	url = {https://arxiv.org/abs/2110.06804},
	volume = {abs/2110.06804},
	year = {2021}
}

@article{OriginalBackPropagation,
	abstract = {The article describes analytic and algorithmic methods for determining the coefficients of the Taylor expansion of an accumulated rounding error with respect to the local rounding errors, and hence determining the influence of the local errors on the accumulated error. Second and higher order coefficients are also discussed, and some possible methods of reducing the extensive storage requirements are analyzed.},
	address = {USA},
	author = {Seppo Linnainmaa},
	doi = {10.1007/BF01931367},
	issn = {0006-3835},
	issue_date = {Jun 1976},
	journal = {BIT},
	keywords = {Storage Requirement, Local Error, Computational Mathematic, Taylor Expansion, Rounding Error},
	month = {jun},
	number = {2},
	numpages = {15},
	pages = {146–160},
	publisher = {BIT Computer Science and Numerical Mathematics},
	title = {Taylor Expansion of the Accumulated Rounding Error},
	url = {https://doi.org/10.1007/BF01931367},
	volume = {16},
	year = {1976}
}

@article{LSTMPaper,
	author = {Sepp Hochreiter and Jürgen Schmidhuber},
	journal = {Neural computation},
	number = {8},
	pages = {1735–1780},
	publisher = {MIT Press},
	title = {Long short-term memory},
	volume = {9},
	year = {1997}
}

@inproceedings{NIPS2012_c399862d,
	author = {Alex Krizhevsky and Ilya Sutskever and Geoffrey E Hinton},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {ImageNet Classification with Deep Convolutional Neural Networks},
	url = {https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
	volume = {25},
	year = {2012}
}

@article{AlphaGoZeroCost,
	author = {Elizabeth Gibney},
	doi = {10.1038/nature.2017.22858},
	journal = {Nature},
	month = {10},
	pages = {},
	title = {Self-taught AI is best yet at strategy game Go},
	year = {2017}
}

@article{SustainableAI,
	author = {Aimee Wynsberghe},
	doi = {10.1007/s43681-021-00043-6},
	journal = {AI and Ethics},
	month = {02},
	pages = {},
	title = {Sustainable AI: AI for sustainability and the sustainability of AI},
	volume = {1},
	year = {2021}
}

@article{BinaryConnectPaper,
	author = {Matthieu Courbariaux and Yoshua Bengio and Jean{-}Pierre David},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/CourbariauxBD15.bib},
	eprint = {1511.00363},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
	title = {BinaryConnect: Training Deep Neural Networks with binary weights during propagations},
	url = {http://arxiv.org/abs/1511.00363},
	volume = {abs/1511.00363},
	year = {2015}
}

@article{BinaryNetPaper,
	author = {Matthieu Courbariaux and Yoshua Bengio},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/CourbariauxB16.bib},
	eprint = {1602.02830},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:46:57 +0200},
	title = {BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1},
	url = {http://arxiv.org/abs/1602.02830},
	volume = {abs/1602.02830},
	year = {2016}
}

@article{XnorNetPaper,
	author = {Mohammad Rastegari and Vicente Ordonez and Joseph Redmon and Ali Farhadi},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/RastegariORF16.bib},
	eprint = {1603.05279},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:22 +0200},
	title = {XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1603.05279},
	volume = {abs/1603.05279},
	year = {2016}
}

@article{ABCNetPaper,
	author = {Xiaofan Lin and Cong Zhao and Wei Pan},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1711-11294.bib},
	eprint = {1711.11294},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:35 +0200},
	title = {Towards Accurate Binary Convolutional Neural Network},
	url = {http://arxiv.org/abs/1711.11294},
	volume = {abs/1711.11294},
	year = {2017}
}

@article{BiRealNetPaper,
	author = {Zechun Liu and Baoyuan Wu and Wenhan Luo and Xin Yang and Wei Liu and Kwang{-}Ting Cheng},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1808-00278.bib},
	eprint = {1808.00278},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Thu, 12 Sep 2019 15:28:48 +0200},
	title = {Bi-Real Net: Enhancing the Performance of 1-bit CNNs With Improved Representational Capability and Advanced Training Algorithm},
	url = {http://arxiv.org/abs/1808.00278},
	volume = {abs/1808.00278},
	year = {2018}
}

@article{STEPaper,
	author = {Yoshua Bengio and Nicholas Léonard and Aaron C. Courville},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/BengioLC13.bib},
	eprint = {1308.3432},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Mon, 13 Aug 2018 16:47:35 +0200},
	title = {Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation},
	url = {http://arxiv.org/abs/1308.3432},
	volume = {abs/1308.3432},
	year = {2013}
}

@article{AdamOptimizer,
	author = {Diederik P. Kingma and Jimmy Ba},
	journal = {CoRR},
	title = {Adam: A Method for Stochastic Optimization},
	volume = {abs/1412.6980},
	year = {2015}
}

@article{BopOptimizer,
	author = {Koen Helwegen and James Widdicombe and Lukas Geiger and Zechun Liu and Kwang{-}Ting Cheng and Roeland Nusselder},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	biburl = {https://dblp.org/rec/journals/corr/abs-1906-02107.bib},
	eprint = {1906.02107},
	eprinttype = {arXiv},
	journal = {CoRR},
	timestamp = {Thu, 13 Jun 2019 13:36:00 +0200},
	title = {Latent Weights Do Not Exist: Rethinking Binarized Neural Network Optimization},
	url = {http://arxiv.org/abs/1906.02107},
	volume = {abs/1906.02107},
	year = {2019}
}

@article{MFCC,
	abstract = {Standard Mel frequency cepstrum coefficient (MFCC) computation technique utilizes discrete cosine transform (DCT) for decorrelating log energies of filter bank output. The use of DCT is reasonable here as the covariance matrix of Mel filter bank log energy (MFLE) can be compared with that of highly correlated Markov-I process. This full-band based MFCC computation technique where each of the filter bank output has contribution to all coefficients, has two main disadvantages. First, the covariance matrix of the log energies does not exactly follow Markov-I property. Second, full-band based MFCC feature gets severely degraded when speech signal is corrupted with narrow-band channel noise, though few filter bank outputs may remain unaffected. In this work, we have studied a class of linear transformation techniques based on block wise transformation of MFLE which effectively decorrelate the filter bank log energies and also capture speech information in an efficient manner. A thorough study has been carried out on the block based transformation approach by investigating a new partitioning technique that highlights associated advantages. This article also reports a novel feature extraction scheme which captures complementary information to wide band information; that otherwise remains undetected by standard MFCC and proposed block transform (BT) techniques. The proposed features are evaluated on NIST SRE databases using Gaussian mixture model-universal background model (GMM-UBM) based speaker recognition system. We have obtained significant performance improvement over baseline features for both matched and mismatched condition, also for standard and narrow-band noises. The proposed method achieves significant performance improvement in presence of narrow-band noise when clubbed with missing feature theory based score computation scheme.},
	author = {Md. Sahidullah and Goutam Saha},
	doi = {10.1016/j.specom.2011.11.004},
	issn = {0167-6393},
	journal = {Speech Communication},
	keywords = {Speaker recognition, MFCC, DCT, Correlation matrix, Decorrelation technique, Linear transformation, Block transform, Narrow-band noise, Missing feature theory},
	number = {4},
	pages = {543–565},
	title = {Design, analysis and experimental evaluation of block based transformation in MFCC computation for speaker recognition},
	url = {https://www.sciencedirect.com/science/article/pii/S0167639311001622},
	volume = {54},
	year = {2012}
}

@misc{11,
	author = {IBM},
	howpublished = {\url{https://www.ibm.com/docs/fr/spss-modeler/saas?topic=dm-crisp-help-overview}},
	title = {Présentation générale de CRISP-DM},
	year = {2017}
}

@misc{12,
	author = {Yann LeCun},
	howpublished = {\url{http://yann.lecun.com/exdb/mnist}},
	title = {THE MNIST DATABASE},
	year = {1998}
}

@misc{13,
	author = {Zohar Jackson},
	howpublished = {\url{https://github.com/Jakobovski/free-spoken-digit-dataset}},
	title = {Free Spoken Digits Dataset},
	year = {2019}
}

@article{OmegaSpecsMPG,
	abstract = {Multi-player mean-payoff games are a natural formalism for modelling the behaviour of concurrent and multi-agent systems with self-interested players. Players in such a game traverse a graph, while attempting to maximise a (mean-)payoff function that depends on the play generated. As with all games, the equilibria that could arise may have undesirable properties. However, as system designers, we typically wish to ensure that equilibria in such systems correspond to desirable system behaviours, for example, satisfying certain safety or liveness properties. One natural way to do this would be to specify such desirable properties using temporal logic. Unfortunately, the use of temporal logic specifications causes game theoretic verification problems to have very high computational complexity. To address this issue, we consider \&omega;-regular specifications. These offer a concise and intuitive way of specifying system behaviours with a comparatively low computational overhead. The main results of this work are characterisation and complexity bounds for the problem of determining if there are equilibria that satisfy a given \&omega;-regular specification in a multi-player mean-payoff game in a number of computationally relevant game-theoretic settings.},
	article-number = {19},
	author = {Julian Gutierrez and Thomas Steeples and Michael Wooldridge},
	doi = {10.3390/g13010019},
	issn = {2073-4336},
	journal = {Games},
	number = {1},
	title = {Mean-Payoff Games with \&omega;-Regular Specifications},
	url = {https://www.mdpi.com/2073-4336/13/1/19},
	volume = {13},
	year = {2022}
}

@article{MPGMaxAtom,
	author = {Albert Atserias and Elitza Maneva},
	month = {01},
	pages = {},
	title = {Mean-Payoff Games and the Max-Atom Problem},
	year = {2009}
}

@article{SimplexMPG,
	author = {Xavier Allamigeon and Pascal Benchimol and Stéphane Gaubert and Michael Joswig},
	doi = {10.1137/140953800},
	eprint = { https://doi.org/10.1137/140953800 },
	journal = {SIAM Journal on Optimization},
	number = {4},
	pages = {2096–2117},
	title = {Combinatorial Simplex Algorithms Can Solve Mean Payoff Games},
	url = { 
    
        https://doi.org/10.1137/140953800
    
    

},
	volume = {24},
	year = {2014}
}

@inproceedings{ComputationalComplexityMPG,
	abstract = {We study the complexity of finding the values and optimal strategies of mean payoff games, a family of perfect information games introduced by Ehrenfeucht and Mycielski. We describe a pseudopolynomial time algorithm for the solution of such games, the decision problem for which is in NP ∩ co-NP. Finally, we describe a polynomial reduction from mean payoff games to the simple stochastic games studied by Condon. These games are also known to be in NP ∩ co-NP, but no polynomial or pseudo-polynomial time algorithm is known for them.},
	address = {Berlin, Heidelberg},
	author = {Uri Zwick and Michael S. Paterson},
	booktitle = {Computing and Combinatorics},
	editor = {Ding-Zhu Du and Ming Li},
	isbn = {978-3-540-44733-7},
	pages = {1–10},
	publisher = {Springer Berlin Heidelberg},
	title = {The complexity of mean payoff games},
	year = {1995}
}

@inproceedings{StrategyImprovement,
	abstract = {This paper presents a novel strategy improvement algorithm for parity and payoff games, which is guaranteed to select, in each improvement step, an optimal combination of local strategy modifications. Current strategy improvement methods stepwise improve the strategy of one player with respect to some ranking function, using an algorithm with two distinct phases: They first choose a modification to the strategy of one player from a list of locally profitable changes, and subsequently evaluate the modified strategy. This separation is unfortunate, because current strategy improvement algorithms have no effective means to predict the global effect of the individual local modifications beyond classifying them as profitable, adversarial, or stale. Furthermore, they are completely blind towards the cross effect of different modifications: Applying one profitable modification may render all other profitable modifications adversarial. Our new construction overcomes the traditional separation between choosing and evaluating the modification to the strategy. It thus improves over current strategy improvement algorithms by providing the optimal improvement in every step, selecting the best combination of local updates from a superset of all profitable and stale changes.},
	address = {Berlin, Heidelberg},
	author = {Sven Schewe},
	booktitle = {Computer Science Logic},
	editor = {Michael Kaminski and Simone Martini},
	isbn = {978-3-540-87531-4},
	pages = {369–384},
	publisher = {Springer Berlin Heidelberg},
	title = {An Optimal Strategy Improvement Algorithm for Solving Parity and Payoff Games},
	year = {2008}
}

@article{StochasticGamesComplexity,
	abstract = {We consider the complexity of stochastic games—simple games of chance played by two players. We show that the problem of deciding which player has the greatest chance of winning the game is in the class NP ⌢ co-NP.},
	author = {Anne Condon},
	doi = {10.1016/0890-5401(92)90048-K},
	issn = {0890-5401},
	journal = {Information and Computation},
	number = {2},
	pages = {203–224},
	title = {The complexity of stochastic games},
	url = {https://www.sciencedirect.com/science/article/pii/089054019290048K},
	volume = {96},
	year = {1992}
}

@article{LatticeProblemsComplexity,
	author = {Dorit Aharonov and Oded Regev},
	doi = {10.1109/FOCS.2004.35},
	journal = {Foundations of Computer Science, 1975., 16th Annual Symposium on},
	month = {05},
	pages = {},
	title = {Lattice Problems in NP cap coNP},
	year = {2004}
}

@misc{NPInterCoNP,
	howpublished = {\url{https://kintali.wordpress.com/2010/06/06/np-intersect-conp/}},
	note = {Accessed: 2023-08-28},
	title = {NP intersect coNP}
}

@book{ArtComputerProgramming,
	address = {USA},
	author = {Donald E. Knuth},
	isbn = {0201896834},
	publisher = {Addison Wesley Longman Publishing Co., Inc.},
	title = {The Art of Computer Programming, Volume 1 (3rd Ed.): Fundamental Algorithms},
	year = {1997}
}

@book{AIModernApproach,
	abstract = {xviii, 1132 pages : illustrations ; 26 cm},
	author = {Stuart J. Russell},
	note = {Includes bibliographical references (pages 1063-1093) and index.},
	publisher = {Third edition. Upper Saddle River, N.J. : Prentice Hall, [2010] ©2010},
	title = {Artificial intelligence : a modern approach},
	url = {https://search.library.wisc.edu/catalog/9910082172502121},
	year = {2010}
}

@article{GNN,
	author = {Benjamin Sanchez-Lengeling and Emily Reif and Adam Pearce and Alexander B. Wiltschko},
	doi = {10.23915/distill.00033},
	journal = {Distill},
	note = {https://distill.pub/2021/gnn-intro},
	title = {A Gentle Introduction to Graph Neural Networks},
	year = {2021}
}

@article{AlphaZero,
	abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo.},
	author = {David Silver and Julian Schrittwieser and Karen Simonyan and Ioannis Antonoglou and Aja Huang and Arthur Guez and Thomas Hubert and Lucas Baker and Matthew Lai and Adrian Bolton and Yutian Chen and Timothy Lillicrap and Fan Hui and Laurent Sifre and George van den Driessche and Thore Graepel and Demis Hassabis},
	day = {01},
	doi = {10.1038/nature24270},
	issn = {1476-4687},
	journal = {Nature},
	month = {Oct},
	number = {7676},
	pages = {354–359},
	title = {Mastering the game of Go without human knowledge},
	url = {https://doi.org/10.1038/nature24270},
	volume = {550},
	year = {2017}
}

